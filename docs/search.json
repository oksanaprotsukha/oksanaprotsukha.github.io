[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Oksana Protsukha",
    "section": "",
    "text": "Useful resources:\nHow to create a website with Quatro"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Oksana Protsukha",
    "section": "",
    "text": "Oksana is deeply passionate about environmental data science and its critical role in the decarbonization and energy sectors. She holds an MBA from San Francisco State University and is currently pursuing a Master’s degree at Bren School. With eight years of experience as a Business Analyst and Technical Product Manager at Tesla Inc., she is now actively pursuing a career pivot into environmental data science. Her goal is to assist companies in addressing data-related challenges within the energy and decarbonization sectors.\n\n\nMaster of Environmental Data Science | University of California, Santa Barbara  Master of Business Administration | California State University, San Francisco"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Oksana Protsukha",
    "section": "",
    "text": "Master of Environmental Data Science | University of California, Santa Barbara  Master of Business Administration | California State University, San Francisco"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Oksana Protsukha",
    "section": "",
    "text": "My projects\n-in progress-"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "posts",
    "section": "",
    "text": "ipynb rendered as html\n\n\nThis post was rendered from a .ipynb file through quarto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpact of the Thomas Fire on AQI in Santa Barbara County, CA (2017)\n\n\n\nGeoSpatial\n\n\nPython\n\n\nWild Fires\n\n\nAir Quality\n\n\n\nData Analysis of Thomas Fire’s Impact on Air Quality Index (AQI) in Santa Barbara County (2017)\n\n\n\nOksana Protsukha\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPowering Through the Dark: Dunkelflaute and Grid Resilience\n\n\n\nEnergy\n\n\nRenewables\n\n\nEnvironmental writing\n\n\n\n\n\n\n\nOksana Protsukha\n\n\nDec 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy first blog post\n\n\n\nR\n\n\nMEDS\n\n\ndelete\n\n\n\nShort description\n\n\n\nOksana Protsukha, Jane Doe\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\nNo matching items\n\nCitationBibTeX citation:@online{untitled,\n  author = {},\n  title = {Posts},\n  url = {https://oksanaprotsukha.github.io/portfolio/projects/2023-11-06-my-first-post.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n“Posts.” n.d. https://oksanaprotsukha.github.io/portfolio/projects/2023-11-06-my-first-post.html."
  },
  {
    "objectID": "posts/2023-11-06-my-first-post/index.html",
    "href": "posts/2023-11-06-my-first-post/index.html",
    "title": "My first blog post",
    "section": "",
    "text": "This is the start of my blog posts. More to follow\n\n\n\nCitationBibTeX citation:@online{protsukha2023,\n  author = {Protsukha, Oksana and Doe, Jane},\n  title = {My First Blog Post},\n  date = {2023-11-06},\n  url = {https://oksanaprotsukha.github.io/portfolio/projects/2023-11-06-my-first-post.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nProtsukha, Oksana, and Jane Doe. 2023. “My First Blog\nPost.” November 6, 2023. https://oksanaprotsukha.github.io/portfolio/projects/2023-11-06-my-first-post.html."
  },
  {
    "objectID": "posts/python_notebook_render/STAC-search.html",
    "href": "posts/python_notebook_render/STAC-search.html",
    "title": "ipynb rendered as html",
    "section": "",
    "text": "Code\nimport numpy as np\nimport geopandas as gpd\nimport rioxarray as rioxr\nimport matplotlib.pyplot as plt\n\nfrom shapely.geometry import Polygon\n\n# used to access STAC catalogs\nfrom pystac_client import Client\n# used fo sign items from the MPC STAC catalog\nimport planetary_computer\n\n# other libraries for nice outputs\nfrom IPython.display import Image\nCode\n## Access\nCode\n# access catalog\ncatalog = Client.open('https://planetarycomputer.microsoft.com/api/stac/v1',\n                      modifier = planetary_computer.sign_inplace)"
  },
  {
    "objectID": "posts/python_notebook_render/STAC-search.html#collection",
    "href": "posts/python_notebook_render/STAC-search.html#collection",
    "title": "ipynb rendered as html",
    "section": "Collection",
    "text": "Collection\nWe can select a single collection for exploration using the get_child() method for the catalog and the collection id aas the parameter.\n\n\nCode\nnaip_collection = catalog.get_child('naip')\nnaip_collection\n\n\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Collection\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"naip\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) provides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR).  NAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) within the [US Department of Agriculture](https://www.usda.gov/) (USDA).  Data are captured at least once every three years for each state.  This dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\n\"\n        \n    \n                \n            \n                \n                    \n        \n            links\n            [] 6 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"license\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://www.fsa.usda.gov/help/policies-and-links/\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Public Domain\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"describedby\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/dataset/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Human readable dataset overview and reference\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/item-assets/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/table/v1.2.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            item_assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            metadata\n            \n        \n            \n                \n        \n            type\n            \"text/plain\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"metadata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"FGDC Metdata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            msft:region\n            \"westeurope\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:container\n            \"naip\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:storage_account\n            \"naipeuwest\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:short_description\n            \"NAIP provides US-wide, high-resolution aerial imagery.  This dataset includes NAIP images from 2010 to the present.\"\n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"NAIP: National Agriculture Imagery Program\"\n        \n    \n                \n            \n                \n                    \n        \n            extent\n            \n        \n            \n                \n        \n            spatial\n            \n        \n            \n                \n        \n            bbox\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -124.784\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            24.744\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -66.951\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            49.346\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            temporal\n            \n        \n            \n                \n        \n            interval\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"2010-01-01T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"2021-12-31T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            license\n            \"proprietary\"\n        \n    \n                \n            \n                \n                    \n        \n            keywords\n            [] 7 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"NAIP\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"Aerial\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"Imagery\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"USDA\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"AFPO\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"Agriculture\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"United States\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            providers\n            [] 3 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"USDA Farm Service Agency\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"producer\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"licensor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Esri\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"processor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.esri.com/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Microsoft\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"host\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"processor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://planetarycomputer.microsoft.com\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            summaries\n            \n        \n            \n                \n        \n            gsd\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            assets\n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edatasetspublicassets.blob.core.windows.net/assets/pc_thumbnails/naip.png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"NAIP thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geoparquet-items\n            \n        \n            \n                \n        \n            href\n            \"abfs://items/naip.parquet\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/x-parquet\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"GeoParquet STAC items\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Snapshot of the collection's STAC items exported to GeoParquet format.\"\n        \n    \n            \n        \n            \n                \n        \n            msft:partition_info\n            \n        \n            \n                \n        \n            is_partitioned\n            True\n        \n    \n            \n        \n            \n                \n        \n            partition_frequency\n            \"AS\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            table:storage_options\n            \n        \n            \n                \n        \n            account_name\n            \"pcstacitems\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"stac-items\""
  },
  {
    "objectID": "posts/python_notebook_render/STAC-search.html#catalog-search",
    "href": "posts/python_notebook_render/STAC-search.html#catalog-search",
    "title": "ipynb rendered as html",
    "section": "Catalog search",
    "text": "Catalog search\nWe can narrow the search within the catalog by specifying a time range, an area of interest, and the collection name. The simplest way to define the area of interest to look in the catalog are:\n\na GeoJSON-type dictionary with the coordinates of the bounding box,\nas a list [xmin, ymin, xmax, ymax] with the coordinate values defining the four corners of the bounding box.\n\nYou could also use a point, or some more complex polygon.\nIn this lab we are going look for NAIP scenes over Santa Barbara from 2018 to 2020. We’ll use GeoJSON method to define the area of interest:\n\n\nCode\n# temporal range of interest\ntime_range = \"2018-01-01/2023-01-01\"\n\n# NCEAS bounding box (as a GeoJSON)\nbbox = {\n    \"type\": \"Polygon\",\n    \"coordinates\":[\n        [\n            [-119.70608227128903, 34.426300194372274],\n            [-119.70608227128903, 34.42041139020533],\n            [-119.6967885126002, 34.42041139020533],\n            [-119.6967885126002, 34.426300194372274],\n            [-119.70608227128903, 34.426300194372274]\n        ]\n    ],\n}\n\n# catalog search\nsearch = catalog.search(\n    collections=['naip'],\n    intersects=bbox,\n    datetime=time_range)\nsearch\n\n\n&lt;pystac_client.item_search.ItemSearch at 0x17bc82810&gt;\n\n\nTo get the items found in the search (or check if there were any matches in the search) we use the item_collection() method:\n\n\nCode\nitems = search.item_collection()\n\n# number of items \nlen(items)\n\n\n2\n\n\n\n\nCode\nitems\n\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    ItemCollection\n                \n            \n            \n\nItems\n\n\n\n\n\nItem: ca_m_3411935_sw_11_060_20200521\n\n\n\nid: ca_m_3411935_sw_11_060_20200521\n\n\nbbox: [-119.754272, 34.371741, -119.683292, 34.440724]\n\n\ngsd: 0.6\n\n\ndatetime: 2020-05-21T00:00:00Z\n\n\nnaip:year: 2020\n\n\nproj:bbox: [246930.0, 3806808.0, 253260.0, 3814296.0]\n\n\nproj:epsg: 26911\n\n\nnaip:state: ca\n\n\nproj:shape: [12480, 10550]\n\n\nproj:transform: [0.6, 0.0, 246930.0, 0.0, -0.6, 3814296.0, 0.0, 0.0, 1.0]\n\n\n\n\nSTAC Extensions\n\n\n\nhttps://stac-extensions.github.io/eo/v1.0.0/schema.json\n\n\nhttps://stac-extensions.github.io/projection/v1.0.0/schema.json\n\n\n\n\n\nAssets\n\n\n\n\n\nAsset: RGBIR COG tile\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.tif?st=2023-11-26T21%3A20%3A49Z&se=2023-12-04T21%3A20%3A50Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A20%3A48Z&ske=2023-12-04T21%3A20%3A48Z&sks=b&skv=2021-06-08&sig=2kcLaAy5fiI4LOoyFNeWCIAwC0gi6/vTkqmGrUJntoY%3D\n\n\ntype: image/tiff; application=geotiff; profile=cloud-optimized\n\n\ntitle: RGBIR COG tile\n\n\nroles: ['data']\n\n\nowner: ca_m_3411935_sw_11_060_20200521\n\n\neo:bands: [{'name': 'Red', 'common_name': 'red'}, {'name': 'Green', 'common_name': 'green'}, {'name': 'Blue', 'common_name': 'blue'}, {'name': 'NIR', 'common_name': 'nir', 'description': 'near-infrared'}]\n\n\n\n\n\n\n\n\n\n\nAsset: Thumbnail\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.200.jpg?st=2023-11-26T21%3A20%3A49Z&se=2023-12-04T21%3A20%3A50Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A20%3A48Z&ske=2023-12-04T21%3A20%3A48Z&sks=b&skv=2021-06-08&sig=2kcLaAy5fiI4LOoyFNeWCIAwC0gi6/vTkqmGrUJntoY%3D\n\n\ntype: image/jpeg\n\n\ntitle: Thumbnail\n\n\nroles: ['thumbnail']\n\n\nowner: ca_m_3411935_sw_11_060_20200521\n\n\n\n\n\n\n\n\n\n\nAsset: TileJSON with default rendering\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: application/json\n\n\ntitle: TileJSON with default rendering\n\n\nroles: ['tiles']\n\n\nowner: ca_m_3411935_sw_11_060_20200521\n\n\n\n\n\n\n\n\n\n\nAsset: Rendered preview\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: image/png\n\n\ntitle: Rendered preview\n\n\nroles: ['overview']\n\n\nowner: ca_m_3411935_sw_11_060_20200521\n\n\nrel: preview\n\n\n\n\n\n\n\nLinks\n\n\n\n\n\nLink:\n\n\n\nrel: collection\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: parent\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink: Microsoft Planetary Computer STAC API\n\n\n\nrel: root\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1\n\n\ntype: application/json\n\n\ntitle: Microsoft Planetary Computer STAC API\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: self\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20200521\n\n\ntype: application/geo+json\n\n\n\n\n\n\n\n\n\n\nLink: Map of item\n\n\n\nrel: preview\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20200521\n\n\ntype: text/html\n\n\ntitle: Map of item\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem: ca_m_3411935_sw_11_060_20180724_20190209\n\n\n\nid: ca_m_3411935_sw_11_060_20180724_20190209\n\n\nbbox: [-119.753736, 34.372185, -119.683827, 34.44028]\n\n\ngsd: 0.6\n\n\ndatetime: 2018-07-24T00:00:00Z\n\n\nnaip:year: 2018\n\n\nproj:bbox: [246978.0, 3806856.0, 253212.0, 3814248.0]\n\n\nproj:epsg: 26911\n\n\nnaip:state: ca\n\n\nproj:shape: [12320, 10390]\n\n\nproj:transform: [0.6, 0.0, 246978.0, 0.0, -0.6, 3814248.0, 0.0, 0.0, 1.0]\n\n\n\n\nSTAC Extensions\n\n\n\nhttps://stac-extensions.github.io/eo/v1.0.0/schema.json\n\n\nhttps://stac-extensions.github.io/projection/v1.0.0/schema.json\n\n\n\n\n\nAssets\n\n\n\n\n\nAsset: RGBIR COG tile\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_060cm_2018/34119/m_3411935_sw_11_060_20180724_20190209.tif?st=2023-11-26T21%3A20%3A49Z&se=2023-12-04T21%3A20%3A50Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A20%3A48Z&ske=2023-12-04T21%3A20%3A48Z&sks=b&skv=2021-06-08&sig=2kcLaAy5fiI4LOoyFNeWCIAwC0gi6/vTkqmGrUJntoY%3D\n\n\ntype: image/tiff; application=geotiff; profile=cloud-optimized\n\n\ntitle: RGBIR COG tile\n\n\nroles: ['data']\n\n\nowner: ca_m_3411935_sw_11_060_20180724_20190209\n\n\neo:bands: [{'name': 'Red', 'common_name': 'red'}, {'name': 'Green', 'common_name': 'green'}, {'name': 'Blue', 'common_name': 'blue'}, {'name': 'NIR', 'common_name': 'nir', 'description': 'near-infrared'}]\n\n\n\n\n\n\n\n\n\n\nAsset: FGDC Metdata\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_fgdc_2018/34119/m_3411935_sw_11_060_20180724.txt?st=2023-11-26T21%3A20%3A49Z&se=2023-12-04T21%3A20%3A50Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A20%3A48Z&ske=2023-12-04T21%3A20%3A48Z&sks=b&skv=2021-06-08&sig=2kcLaAy5fiI4LOoyFNeWCIAwC0gi6/vTkqmGrUJntoY%3D\n\n\ntype: text/plain\n\n\ntitle: FGDC Metdata\n\n\nroles: ['metadata']\n\n\nowner: ca_m_3411935_sw_11_060_20180724_20190209\n\n\n\n\n\n\n\n\n\n\nAsset: Thumbnail\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_060cm_2018/34119/m_3411935_sw_11_060_20180724_20190209.200.jpg?st=2023-11-26T21%3A20%3A49Z&se=2023-12-04T21%3A20%3A50Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A20%3A48Z&ske=2023-12-04T21%3A20%3A48Z&sks=b&skv=2021-06-08&sig=2kcLaAy5fiI4LOoyFNeWCIAwC0gi6/vTkqmGrUJntoY%3D\n\n\ntype: image/jpeg\n\n\ntitle: Thumbnail\n\n\nroles: ['thumbnail']\n\n\nowner: ca_m_3411935_sw_11_060_20180724_20190209\n\n\n\n\n\n\n\n\n\n\nAsset: TileJSON with default rendering\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: application/json\n\n\ntitle: TileJSON with default rendering\n\n\nroles: ['tiles']\n\n\nowner: ca_m_3411935_sw_11_060_20180724_20190209\n\n\n\n\n\n\n\n\n\n\nAsset: Rendered preview\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: image/png\n\n\ntitle: Rendered preview\n\n\nroles: ['overview']\n\n\nowner: ca_m_3411935_sw_11_060_20180724_20190209\n\n\nrel: preview\n\n\n\n\n\n\n\nLinks\n\n\n\n\n\nLink:\n\n\n\nrel: collection\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: parent\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink: Microsoft Planetary Computer STAC API\n\n\n\nrel: root\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1\n\n\ntype: application/json\n\n\ntitle: Microsoft Planetary Computer STAC API\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: self\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20180724_20190209\n\n\ntype: application/geo+json\n\n\n\n\n\n\n\n\n\n\nLink: Map of item\n\n\n\nrel: preview\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209\n\n\ntype: text/html\n\n\ntitle: Map of item"
  },
  {
    "objectID": "posts/python_notebook_render/STAC-search.html#items",
    "href": "posts/python_notebook_render/STAC-search.html#items",
    "title": "ipynb rendered as html",
    "section": "Items",
    "text": "Items\nLet’s get the first item in the search\n\n\nCode\n# get the first item in the catalog search\nitem = items[0]\ntype(item)\n\n\npystac.item.Item\n\n\nRemember: the STAC item is the core object of the catalog. The item does not contain the data itself, but rather metadata about the item and links to access the actual data. Some of the metadata:\n\n\nCode\nprint('id', item.id)\nitem.properties\n\n\nid ca_m_3411935_sw_11_060_20200521\n\n\n{'gsd': 0.6,\n 'datetime': '2020-05-21T00:00:00Z',\n 'naip:year': '2020',\n 'proj:bbox': [246930.0, 3806808.0, 253260.0, 3814296.0],\n 'proj:epsg': 26911,\n 'naip:state': 'ca',\n 'proj:shape': [12480, 10550],\n 'proj:transform': [0.6, 0.0, 246930.0, 0.0, -0.6, 3814296.0, 0.0, 0.0, 1.0]}\n\n\n\n\nCode\nitem.assets\n\n\n{'image': &lt;Asset href=https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.tif?st=2023-11-28T21%3A45%3A03Z&se=2023-11-29T22%3A30%3A03Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-29T13%3A45%3A40Z&ske=2023-12-06T13%3A45%3A40Z&sks=b&skv=2021-06-08&sig=OU28gjf8cvXHXJ9yN4B4wAB5ILA7T%2B1BcRSa0SR2JLY%3D&gt;,\n 'thumbnail': &lt;Asset href=https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.200.jpg?st=2023-11-28T21%3A45%3A03Z&se=2023-11-29T22%3A30%3A03Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-29T13%3A45%3A40Z&ske=2023-12-06T13%3A45%3A40Z&sks=b&skv=2021-06-08&sig=OU28gjf8cvXHXJ9yN4B4wAB5ILA7T%2B1BcRSa0SR2JLY%3D&gt;,\n 'tilejson': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png&gt;,\n 'rendered_preview': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png&gt;}\n\n\n\n\nCode\nfor key in item.assets.keys():\n    print(key, '--', item.assets[key].title)\n\n\nimage -- RGBIR COG tile\nthumbnail -- Thumbnail\ntilejson -- TileJSON with default rendering\nrendered_preview -- Rendered preview\n\n\n\n\nCode\nitem.assets.keys()\n\n\ndict_keys(['image', 'thumbnail', 'tilejson', 'rendered_preview'])\n\n\n\n\nCode\nitem.assets['image'].title\n\n\n'RGBIR COG tile'\n\n\nNotice each asset has an href, which is a link to the asset object (ie. the data). For example, we can use the URL for the rendered preview asset to plot it:\n\n\nCode\nImage(url=item.assets['rendered_preview'].href, width=500)"
  },
  {
    "objectID": "posts/python_notebook_render/STAC-search.html#load-data",
    "href": "posts/python_notebook_render/STAC-search.html#load-data",
    "title": "ipynb rendered as html",
    "section": "Load data",
    "text": "Load data\nthe raster data in our current item is in the image asset. Again, we access this data via url. This time we open it using rioxr.open_raster() directly:\n\n\nCode\nsb = rioxr.open_rasterio(item.assets['image'].href)\nsb\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 4, y: 12480, x: 10550)&gt;\n[526656000 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 1 2 3 4\n  * x            (x) float64 2.469e+05 2.469e+05 ... 2.533e+05 2.533e+05\n  * y            (y) float64 3.814e+06 3.814e+06 ... 3.807e+06 3.807e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:             Area\n    TIFFTAG_IMAGEDESCRIPTION:  OrthoVista\n    TIFFTAG_RESOLUTIONUNIT:    1 (unitless)\n    TIFFTAG_SOFTWARE:          Trimble Germany GmbH\n    TIFFTAG_XRESOLUTION:       1\n    TIFFTAG_YRESOLUTION:       1\n    _FillValue:                0\n    scale_factor:              1.0\n    add_offset:                0.0xarray.DataArrayband: 4y: 12480x: 10550...[526656000 values with dtype=uint8]Coordinates: (4)band(band)int641 2 3 4array([1, 2, 3, 4])x(x)float642.469e+05 2.469e+05 ... 2.533e+05array([246930.3, 246930.9, 246931.5, ..., 253258.5, 253259.1, 253259.7])y(y)float643.814e+06 3.814e+06 ... 3.807e+06array([3814295.7, 3814295.1, 3814294.5, ..., 3806809.5, 3806808.9, 3806808.3])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :246930.0 0.6 0.0 3814296.0 0.0 -0.6array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1, 2, 3, 4], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([          246930.3,           246930.9,           246931.5,\n       246932.09999999998, 246932.69999999998,           246933.3,\n                 246933.9,           246934.5, 246935.09999999998,\n       246935.69999999998,\n       ...\n                 253254.3,           253254.9,           253255.5,\n       253256.09999999998, 253256.69999999998,           253257.3,\n                 253257.9,           253258.5, 253259.09999999998,\n       253259.69999999998],\n      dtype='float64', name='x', length=10550))yPandasIndexPandasIndex(Index([         3814295.7,          3814295.1,          3814294.5,\n       3814293.9000000004, 3814293.3000000003,          3814292.7,\n                3814292.1,          3814291.5, 3814290.9000000004,\n       3814290.3000000003,\n       ...\n                3806813.7,          3806813.1,          3806812.5,\n       3806811.9000000004, 3806811.3000000003,          3806810.7,\n                3806810.1,          3806809.5, 3806808.9000000004,\n       3806808.3000000003],\n      dtype='float64', name='y', length=12480))Attributes: (9)AREA_OR_POINT :AreaTIFFTAG_IMAGEDESCRIPTION :OrthoVistaTIFFTAG_RESOLUTIONUNIT :1 (unitless)TIFFTAG_SOFTWARE :Trimble Germany GmbHTIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1_FillValue :0scale_factor :1.0add_offset :0.0\n\n\n\n\nCode\n# plot raster with correct ratio\nsize = 6 # height in in of plot height\naspect = sb.rio.width / sb.rio.height \n# select R,G,B bands and plot\nsb.sel(band=[1,2,3]).plot.imshow(size=size, aspect=aspect)"
  },
  {
    "objectID": "posts/python_notebook_render/STAC-search.html#exercise",
    "href": "posts/python_notebook_render/STAC-search.html#exercise",
    "title": "ipynb rendered as html",
    "section": "Exercise",
    "text": "Exercise\nThe cop-dem-glo-90 (id of the collection) contains the Copernicus DEM at 90m resolution (the one we used for Grand Canyon).\n\nReuse the bbox for Santa Barbara to look for items in this collection.\nGet the first item in the search and check its assets.\nCheck the item’s rendered preview asset by clicking on it’s URL.\nOpen the item’s data using rioxarray.\n\n\n\nCode\n# catalog search\nsearch2 = catalog.search(\n    collections=['cop-dem-glo-90'],\n    intersects=bbox,\n    datetime=time_range)\nsearch2\n\nitems2 = search2.item_collection()\n\n# number of items \nlen(items2)\n\n\n1\n\n\n\n\nCode\nitem2 = items2[0]\ntype(item2)\n\n\npystac.item.Item\n\n\n\n\nCode\nitem2.assets\n\n\n{'data': &lt;Asset href=https://elevationeuwest.blob.core.windows.net/copernicus-dem/COP90_hh/Copernicus_DSM_COG_30_N34_00_W120_00_DEM.tif?st=2023-11-26T21%3A44%3A42Z&se=2023-12-04T21%3A44%3A42Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A44%3A41Z&ske=2023-12-04T21%3A44%3A41Z&sks=b&skv=2021-06-08&sig=6ZTP1TCjtgMcILEivkVJshb/9ajT3kuVecLRiFkGBWc%3D&gt;,\n 'tilejson': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=cop-dem-glo-90&item=Copernicus_DSM_COG_30_N34_00_W120_00_DEM&assets=data&colormap_name=terrain&rescale=-1000%2C4000&format=png&gt;,\n 'rendered_preview': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=cop-dem-glo-90&item=Copernicus_DSM_COG_30_N34_00_W120_00_DEM&assets=data&colormap_name=terrain&rescale=-1000%2C4000&format=png&gt;}\n\n\n\n\nCode\n# Open the item’s data using rioxarray\nsb2 = rioxr.open_rasterio(item2.assets['data'].href)\nsb2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 1200, x: 1200)&gt;\n[1440000 values with dtype=float32]\nCoordinates:\n  * band         (band) int64 1\n  * x            (x) float64 -120.0 -120.0 -120.0 ... -119.0 -119.0 -119.0\n  * y            (y) float64 35.0 35.0 35.0 35.0 35.0 ... 34.0 34.0 34.0 34.0\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:  Point\n    scale_factor:   1.0\n    add_offset:     0.0xarray.DataArrayband: 1y: 1200x: 1200...[1440000 values with dtype=float32]Coordinates: (4)band(band)int641array([1])x(x)float64-120.0 -120.0 ... -119.0 -119.0array([-120.      , -119.999167, -119.998333, ..., -119.0025  , -119.001667,\n       -119.000833])y(y)float6435.0 35.0 35.0 ... 34.0 34.0 34.0array([35.      , 34.999167, 34.998333, ..., 34.0025  , 34.001667, 34.000833])spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-120.00041666666667 0.0008333333333333334 0.0 35.000416666666666 0.0 -0.0008333333333333334array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([             -120.0, -119.99916666666667, -119.99833333333333,\n                 -119.9975, -119.99666666666667, -119.99583333333334,\n                  -119.995, -119.99416666666667, -119.99333333333334,\n                 -119.9925,\n       ...\n       -119.00833333333334,           -119.0075, -119.00666666666666,\n       -119.00583333333333,            -119.005, -119.00416666666666,\n       -119.00333333333333,           -119.0025, -119.00166666666667,\n       -119.00083333333333],\n      dtype='float64', name='x', length=1200))yPandasIndexPandasIndex(Index([              35.0,  34.99916666666667, 34.998333333333335,\n                  34.9975,  34.99666666666667,  34.99583333333333,\n                   34.995, 34.994166666666665,  34.99333333333333,\n                  34.9925,\n       ...\n        34.00833333333333,            34.0075,  34.00666666666667,\n       34.005833333333335,             34.005,  34.00416666666667,\n        34.00333333333333,            34.0025, 34.001666666666665,\n        34.00083333333333],\n      dtype='float64', name='y', length=1200))Attributes: (3)AREA_OR_POINT :Pointscale_factor :1.0add_offset :0.0\n\n\n\n\nCode\nImage(url=item2.assets['rendered_preview'].href, width=500)\n\n\n\n\n\n\n\nCode\nsb2.sel(band=[1]).plot()\n\n\n&lt;matplotlib.collections.QuadMesh at 0x7e780064bc10&gt;"
  },
  {
    "objectID": "posts/python_notebook_render/STAC-search.html#exploration",
    "href": "posts/python_notebook_render/STAC-search.html#exploration",
    "title": "ipynb rendered as html",
    "section": "Exploration",
    "text": "Exploration\n\n\nCode\n# metadata from the catalog\nprint('Title:', catalog.title)\nprint('Description:', catalog.description)\n\n\nTitle: Microsoft Planetary Computer STAC API\nDescription: Searchable spatiotemporal metadata describing Earth science datasets hosted by the Microsoft Planetary Computer\n\n\nWe can access the catalog’s collections by using get_collections() method\n\n\nCode\ncatalog.get_collections()\n\n\n&lt;generator object Client.get_collections at 0x7e78023f3cd0&gt;\n\n\nNotice: the output of get_collections() is generator.\nThis is a special kind of lazy object in Python over which you can loop over like a list. Unlike a list, the items in a generator do not exist in memory until you explicitely iterate over them or convert them to a list. Let’s try getting the collections from the catalog again:\n\n\nCode\n# get collections and print their names\ncollections = list(catalog.get_collections())\n\nprint('Number of collections: ', len(collections))\nprint('Collections IDs:')\n\nfor collection in collections:\n    print('-', collection.id)\n\n\nNumber of collections:  122\nCollections IDs:\n- daymet-annual-pr\n- daymet-daily-hi\n- 3dep-seamless\n- 3dep-lidar-dsm\n- fia\n- sentinel-1-rtc\n- gridmet\n- daymet-annual-na\n- daymet-monthly-na\n- daymet-annual-hi\n- daymet-monthly-hi\n- daymet-monthly-pr\n- gnatsgo-tables\n- hgb\n- cop-dem-glo-30\n- cop-dem-glo-90\n- goes-cmi\n- terraclimate\n- nasa-nex-gddp-cmip6\n- gpm-imerg-hhr\n- gnatsgo-rasters\n- 3dep-lidar-hag\n- 3dep-lidar-intensity\n- 3dep-lidar-pointsourceid\n- mtbs\n- noaa-c-cap\n- 3dep-lidar-copc\n- modis-64A1-061\n- alos-fnf-mosaic\n- 3dep-lidar-returns\n- mobi\n- landsat-c2-l2\n- era5-pds\n- chloris-biomass\n- kaza-hydroforecast\n- planet-nicfi-analytic\n- modis-17A2H-061\n- modis-11A2-061\n- daymet-daily-pr\n- 3dep-lidar-dtm-native\n- 3dep-lidar-classification\n- 3dep-lidar-dtm\n- gap\n- modis-17A2HGF-061\n- planet-nicfi-visual\n- gbif\n- modis-17A3HGF-061\n- modis-09A1-061\n- alos-dem\n- alos-palsar-mosaic\n- deltares-water-availability\n- modis-16A3GF-061\n- modis-21A2-061\n- us-census\n- jrc-gsw\n- deltares-floods\n- modis-43A4-061\n- modis-09Q1-061\n- modis-14A1-061\n- hrea\n- modis-13Q1-061\n- modis-14A2-061\n- sentinel-2-l2a\n- modis-15A2H-061\n- modis-11A1-061\n- modis-15A3H-061\n- modis-13A1-061\n- daymet-daily-na\n- nrcan-landcover\n- modis-10A2-061\n- ecmwf-forecast\n- noaa-mrms-qpe-24h-pass2\n- sentinel-1-grd\n- nasadem\n- io-lulc\n- landsat-c2-l1\n- drcog-lulc\n- chesapeake-lc-7\n- chesapeake-lc-13\n- chesapeake-lu\n- noaa-mrms-qpe-1h-pass1\n- noaa-mrms-qpe-1h-pass2\n- noaa-nclimgrid-monthly\n- goes-glm\n- usda-cdl\n- eclipse\n- esa-cci-lc\n- esa-cci-lc-netcdf\n- fws-nwi\n- usgs-lcmap-conus-v13\n- usgs-lcmap-hawaii-v10\n- noaa-climate-normals-tabular\n- noaa-climate-normals-netcdf\n- noaa-climate-normals-gridded\n- aster-l1t\n- cil-gdpcir-cc-by-sa\n- io-lulc-9-class\n- io-biodiversity\n- naip\n- noaa-cdr-sea-surface-temperature-whoi\n- noaa-cdr-ocean-heat-content\n- cil-gdpcir-cc0\n- cil-gdpcir-cc-by\n- noaa-cdr-sea-surface-temperature-whoi-netcdf\n- noaa-cdr-sea-surface-temperature-optimum-interpolation\n- modis-10A1-061\n- sentinel-5p-l2-netcdf\n- sentinel-3-olci-wfr-l2-netcdf\n- noaa-cdr-ocean-heat-content-netcdf\n- sentinel-3-synergy-aod-l2-netcdf\n- sentinel-3-synergy-v10-l2-netcdf\n- sentinel-3-olci-lfr-l2-netcdf\n- sentinel-3-sral-lan-l2-netcdf\n- sentinel-3-slstr-lst-l2-netcdf\n- sentinel-3-slstr-wst-l2-netcdf\n- sentinel-3-sral-wat-l2-netcdf\n- ms-buildings\n- sentinel-3-slstr-frp-l2-netcdf\n- sentinel-3-synergy-syn-l2-netcdf\n- sentinel-3-synergy-vgp-l2-netcdf\n- sentinel-3-synergy-vg1-l2-netcdf\n- esa-worldcover"
  },
  {
    "objectID": "posts/2023-12-08-dunkelflaute/index.html",
    "href": "posts/2023-12-08-dunkelflaute/index.html",
    "title": "Powering Through the Dark: Dunkelflaute and Grid Resilience",
    "section": "",
    "text": "In 2015 the International Energy Agency (IEA) welcomed the landmark Paris Agreement with the quote, “The Paris Agreement is nothing less than a historic milestone for the global energy sector. It will speed up the transformation of the energy sector by accelerating investments in cleaner technologies and energy efficiency.” The IEA should know: the organization estimates that the energy sector is the single largest emitter of greenhouse gases (GHG), accounting for three quarters of all GHG emissions globally. Meeting climate targets requires that 70 % of global electricity generation come from wind and solar combined according to the IEA 2050 zero emissions scenario. Fortunately, we have seen unprecedented growth in both solar and wind energy in recent years, reaching 12% of global electricity generation in 2022. But the sun does not always shine and the wind does not always blow. Some worry that overreliance on renewable energy sources, which are intermittent in nature, will cause grid reliability problems.\nDunkelflaute, a German word that translates to “dark doldrums”, describes a period of simultaneous reduction in wind and solar power generation. This period typically occurs during the winter months when there is less sunlight and low wind. Renewable energy sources do not produce sufficient electricity during a Dunkelflaute, and this poses challenges to balance the grid and effectively respond to energy demands. Though the occurrence of these conditions is rare, usually five consecutive days once a year, the damage can be significant. In February 2021, the Texas grid experienced a major power outage during a winter storm. Power plants across the state failed to operate in the extreme cold temperatures, leaving more than 10 million people without electricity at the peak of the winter storm, with some enduring several days without power. Services dependent on electricity such as drinking water treatment and medical services were affected as well. More than 200 people died directly or indirectly as a result of the crisis. Even though this event was not caused by the intermittent nature of renewable energy generation, it provides an example of what could happen when a grid is not able to meet energy demand when it is needed the most. Still, there are rays of hope in potential solutions.\nNot all gloom Researchers from the Delft University of Technology identified possible solutions to mitigate Dunkelflaute’s effect on energy demand supply. The research suggests that meteorological conditions are not necessarily the same across all European countries. This allows countries to optimize energy supply lines with each other. For instance, when there is low solar radiation and still weather in Northern Germany, the South of France might experience sunny and windy conditions. Tight coordination between the two countries would allow France to divert excess energy from its grid to Germany.\n\n\n\n\n\nOther methods to mitigate the effects of low energy production due to prolonged unfavorable meteorological conditions are available or under investigation. Utility-scale energy storage, such as lithium-ion battery installations and salt caverns, can help in balancing the grid during periods of high demand and low energy production. Salt caverns, large underground salt deposits, can be used as hydrogen holding tanks according to the researchers at the University of Texas at Austin’s Bureau of Economic Geology. These energy banks can be used to store energy during the periods of low demand and release it during high demand when energy production is insufficient. Direct-current-type ultra-high-voltage (UHVDC) transmission lines for global energy transition and climate change is another solution that promises to distribute renewable energy to where it is needed the most.\nWhile the transition to renewable energy sources poses its challenges, the benefits are undeniable: cleaner air, reduced levels of pollution, decrease in GHG emissions, and more equitable energy distribution warrant more innovation to ensure grid reliability. Advancements in energy storage, demand management, and meteorological forecasting will enable grid operators to transition to green energy sources. However, it is crucial to recognize that urgent action is needed to ensure that utilities are well-prepared for this transition without compromising the wellbeing of their customers.\n\n\n\nCitationBibTeX citation:@online{protsukha2023,\n  author = {Protsukha, Oksana},\n  title = {Powering {Through} the {Dark:} {Dunkelflaute} and {Grid}\n    {Resilience}},\n  date = {2023-12-08},\n  url = {https://oksanaprotsukha.github.io/portfolio/projects/2023-11-06-my-first-post.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nProtsukha, Oksana. 2023. “Powering Through the Dark: Dunkelflaute\nand Grid Resilience.” December 8, 2023. https://oksanaprotsukha.github.io/portfolio/projects/2023-11-06-my-first-post.html."
  },
  {
    "objectID": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html",
    "href": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html",
    "title": "Impact of the Thomas Fire on AQI in Santa Barbara County, CA (2017)",
    "section": "",
    "text": "Author: Oksana Protsukha\nGithub repository: https://github.com/oksanaprotsukha/thomasfire_aqi_analysis\n\n\nIn this notebook, we are going to analyze the impact of Thomas Fire on the air quality in Santa Barbara county in 2017. To do so, we will complete the following two tasks: 1. Visualize the Air Quality Index (AQI) in Santa Barbara County for 2017 and 2018. 2. Create a map to visualize the Thomas Fire scar.\n\n\nThe primary purpose of the notebook is to demonstrate environmental data analysis methods using both vector and raster data.\n\n\n\n\nPython libraries\n\nnumpy\npandas\npyplot and patches from matplotlib\nrioxarray\ngeopandas\nxarray\n\nJupyter Notebook\nGitHub\n\n\n\n\n\nData wrangling and exploration with Pandas\nGeospatial data wrangling with GeoPandas and Rioxarray\nTime series analysis\nMerging tabular and vector data\nVisualizing analysis results with a line plot\nCreating and customizing a map with raster and vector data\n\n\n\n\n\n\nAir Quality Index (AQI) data from the US Environmental Protection Agency[1] to visualize the impact on the AQI of the 2017 Thomas Fire in Santa Barbara County [2].\n\n\n\nA simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite [3]. Note: data should be used for visualization purposes only.\nInformation about Landsat bands from USGS:\n\nWhat are the band designations for the Landsat satellites?\nCommon Landsat Band Combinations\nHow do I use a scale factor with Landsat Level-2 science products?\n\n\n\n\nA prepared shapefile of fire perimeters in California during 2017. The complete file can be accessed in the CA state geoportal[4].\nData for datasets 2 and 3 is available on Google Drive in the file thomasfire_aqi_analysis.zip.\n\n\n\n\n\nThe final outputs of the analysis include:\n\nA Line Plot depicting the time series analysis of the Air Quality Index (AQI) in Santa Barbara for 2017 and 2018. \nA Map with an overlay of the Thomas Fire scar on the Santa Barbara land cover. \n\n\n\n[1] AirData Website File Download Page. https://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI. Accessed 28 Nov. 2023. [2] “Thomas Fire.” Wikipedia, 9 Nov. 2023. Wikipedia, https://en.wikipedia.org/w/index.php?title=Thomas_Fire&oldid=1184323284. [3] Microsoft Planetary Computer. https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed 28 Nov. 2023. [4] California Fire Perimeters (All). https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about. Accessed 28 Nov. 2023.\n\n\n\n\n\n\nCode\n# import libraries with standard abbreviations\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches # for creating legends\n\nimport rioxarray as rioxr\nimport geopandas as gpd\nimport xarray as xr\n\n\n\n\n\n\n\n\n\nCode\n# import Daily AQI by County data from url: Dataset 1\n# read in 2017 Daily AQI by County\nurl_aqi_17 = 'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip'\naqi_17 = pd.read_csv(url_aqi_17)\n\n# read in 2018 Daily AQI by County\nurl_aqi_18 = 'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip'\naqi_18 = pd.read_csv(url_aqi_18)\n\n\n\n\n\n\n\nCode\n# use rioxarray library to import netCDF file with geospatial features\nfp_lsat = 'data/landsat8-2018-01-26-sb-simplified.nc'\nlsat = rioxr.open_rasterio(fp_lsat)\n\n\n\n\n\n\n\nCode\n# use geopandas to import shape file with California fire perimeters \ncalfire = gpd.read_file(os.path.join(os.getcwd(), 'data', \n                                     'California_Fire_Perimeters_2017',\n                                     'California_Fire_Perimeters_2017.shp'))  \n\n\n\n\n\n\nLet’s take a quick look at the data before we proceed with data wrangling steps.\n\n\nCode\n# view the list of columns \nprint(aqi_17.columns)\n\n# view the first 2 rows of the dataframe aqi_17\naqi_17.head(2)\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object')\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n21\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n\nCode\n# view the list of columns \nprint(aqi_18.columns)\n\n# view the first 2 rows of the dataframe aqi_18\naqi_18.head(2)\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object')\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2018-01-02\n32\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2018-01-05\n34\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\nNotice that we currently have two separate dataframes. However, in order to analyze AQI for the two years, we need to combine them by appending the rows from one dataframe on top of the other. We will use the pandas function pd.concat() to do so.\nImportant: the columns of the two datasets have to match.\n\n\nCode\n# check whether the columns between the two datasets match\nprint(f'Do columns match?\\n {aqi_18.columns == aqi_17.columns} \\n')\n\n# check whether the column datatypes between the two datasets match\nprint(f'Do datatypes of the columns match?\\n{aqi_18.dtypes == aqi_17.dtypes}')\n\n\nDo columns match?\n [ True  True  True  True  True  True  True  True  True  True] \n\nDo datatypes of the columns match?\nState Name                   True\ncounty Name                  True\nState Code                   True\nCounty Code                  True\nDate                         True\nAQI                          True\nCategory                     True\nDefining Parameter           True\nDefining Site                True\nNumber of Sites Reporting    True\ndtype: bool\n\n\nNote: since the column names and datatypes of the two datasets match exaclty we can combine the them into a single dataframe. Let’s check how many records we should expect in the combined dataframe.\n\n\nCode\n# get the count of rows that have state = CA and county = Santa Barbara in the dataframe aqi_17\naqi_17_count = len(aqi_17)\n\n# get the count of rows that have state = CA and county = Santa Barbara in the dataframe aqi_18\naqi_18_count = len(aqi_18)\n\n# get the total count of rows we expect in the combined dataframe\ntot_count = aqi_17_count + aqi_18_count\nprint(f'Combined dataframe should have total number of rows: {tot_count}')  \n\n\nCombined dataframe should have total number of rows: 654338\n\n\n\n\nCode\n# combine two datasets aqi_17 and aqi_18 in a single one\naqi = pd.concat([aqi_17, aqi_18])\n\n# check the total count of rows matches the expected number\naqi_count = len(aqi)\nprint(f'Count of rows in the combined aqi dataframe: {aqi_count}')\nprint(f'Is the total number of rows in the combined dataframe as expected? {aqi_count == tot_count} \\n')\n\n# check the first 2 rows of the combined dataframe\naqi.head(2)\n\n\nCount of rows in the combined aqi dataframe: 654338\nIs the total number of rows in the combined dataframe as expected? True \n\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n21\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\nNotice that column names have inconsistent case and spaces in between the words. Let’s update the column names to snake_case 🐍 to simplify data manipulation.\n\n\nCode\n# update the column names case to snake_case\naqi.columns = aqi.columns.str.lower().str.replace(' ','_')\n# check that the column names are updated\nprint(aqi.columns)\n\n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object')\n\n\nFor our analysis we need only AQI data from the Santa Barbara county. Let’s create a new dataframeaqi_sb filtered to Santa Barbara county. Additionally, we can remove unecessary columns state_name, county_name, state_code and county_code from the new dataframe.\n\n\nCode\n# select the records where county_name = 'Santa Barbara' from the combined dataset aqi\naqi_sb = aqi.loc[aqi.county_name == 'Santa Barbara'].copy()\n\n# remove the state_name, county_name, state_code and county_code columns from aqi_sb\naqi_sb = aqi_sb.drop(columns = ['state_name', 'county_name', 'state_code', 'county_code'])\n\n\n\n\nCode\n# check the data types of the columns\nprint(aqi_sb.dtypes)\n\n\ndate                         object\naqi                           int64\ncategory                     object\ndefining_parameter           object\ndefining_site                object\nnumber_of_sites_reporting     int64\ndtype: object\n\n\n⚠️ Date column has type object rather than datetime as expected.\nWe will make the following changes to facilitate working with dates:\n\nConvert the date column of aqi_sb to a datetime object.\nSet the date column as the index for aqi_sb dataframe.\n\n\n\nCode\n# update date column values of aqi_sb to datetype object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n      \n# update the index of aqi_sb to be the date column\naqi_sb = aqi_sb.set_index('date')\n\n# check column date is updated\nprint(aqi_sb.index)\n\n\nDatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03', '2017-01-04',\n               '2017-01-05', '2017-01-06', '2017-01-07', '2017-01-08',\n               '2017-01-09', '2017-01-10',\n               ...\n               '2018-12-22', '2018-12-23', '2018-12-24', '2018-12-25',\n               '2018-12-26', '2018-12-27', '2018-12-28', '2018-12-29',\n               '2018-12-30', '2018-12-31'],\n              dtype='datetime64[ns]', name='date', length=730, freq=None)\n\n\nOur current dataframe contains daily values of AQI, which can create short-term fluctuations and noise in data. We’ll apply a 5-day rolling average to smooth out the data and improve the quality of the analysis. To achieve this we will create a new variable, five_day_average, using the pandas method rolling.\nNote: rolling() is a method for pandas.series that provides rolling window calculations. This is a lazy method (think groupby), we need to specify what we want to calculate over each window. It returns pd.Series as ouput.\n\n\nCode\n# calculate 5-day rolling average AQI\n# the parameter '5D' indicates we want the window to be 5 days\naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean() \n\n# view the first two rows of the updated dataframe\naqi_sb.head(2)\n\n\n\n\n\n\n\n\n\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\nfive_day_average\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n2017-01-01\n39\nGood\nOzone\n06-083-4003\n12\n39.0\n\n\n2017-01-02\n36\nGood\nOzone\n06-083-4003\n11\n37.5\n\n\n\n\n\n\n\n\n\n\nIn the next step, we will create a line plot with daily AQI and 5-day average AQI to visualize the impact of the Thomas Fire (December 2017) on air quality in Santa Barbara County.\n\n\nCode\n# plot both the daily AQI and the 5-day average\nfig, ax = plt.subplots()\n\naqi_sb.aqi.plot(ax=ax,\n                color = '#fecc5c')\naqi_sb.five_day_average.plot(ax=ax,\n                color = '#a50f15')\n\n# update axis\nax.set_title('Daily Average vs 5 day Average AQI in Santa Barbara (2017-2018)')\nax.set_xlabel('Period')\nax.set_ylabel('AQI')\nax.legend(['AQI Daily Average', 'AQI 5-day Average'])\n\n# annotate the data source\nax.annotate(\"Data: AirData Website File Download Page.\\nhttps://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI. Accessed 28 Nov. 2023\",\n            xy=(0.5, -0.15), \n            fontsize=7, \n            xycoords='axes fraction',  \n            color='#555555',\n            ha='center',\n            va='top')  \n\n# adjust the botton space of the figure\nplt.subplots_adjust(bottom=0.01)\n\nplt.show\n\n\n&lt;function matplotlib.pyplot.show(close=None, block=None)&gt;\n\n\n\n\n\nFrom the graph we can see a significant increase in both the daily average and 5-day rolling average in December 2017 compared to the rest of the year, which coincides with the Thomas Fire event. During this period, the AQI exceeded 200, falling into the very unhealthy category. According to AQI standards, at this level, the risk of health effects is increased for everyone.\n\n\n\nFirst, let’s inspect geospatial datasets.\n\n\nCode\n# view the first two records of imported shape file data\ncalfire.head(2)\n\n\n\n\n\n\n\n\n\nindex\nOBJECTID\nYEAR_\nSTATE\nAGENCY\nUNIT_ID\nFIRE_NAME\nINC_NUM\nALARM_DATE\nCONT_DATE\n...\nGIS_ACRES\nCOMMENTS\nCOMPLEX_NA\nCOMPLEX_IN\nIRWINID\nFIRE_NUM\nDECADES\nSHAPE_Leng\nSHAPE_Area\ngeometry\n\n\n\n\n0\n19836\n41429\n2017\nCA\nCCO\nVNC\nBROOK\n00042450\n2017-05-23\n2017-05-24\n...\n10.043819\nper walked track\nNone\nNone\nNone\nNone\n2010\n1246.055781\n59473.666651\nPOLYGON ((-13229812.974 4046876.486, -13229786...\n\n\n1\n19837\n41430\n2017\nCA\nCCO\nVNC\nPACIFIC\n00075307\n2017-09-09\n2017-09-09\n...\n1.190109\nFinal Walked track. Small spot to the north east\nNone\nNone\nNone\nNone\n2010\n561.418202\n7081.369481\nPOLYGON ((-13286872.985 4074523.355, -13286895...\n\n\n\n\n2 rows × 23 columns\n\n\n\n\n\nCode\nprint(f'calfire dataset shape: {calfire.shape}')\nprint(f'calfire dataset crs: {calfire.crs}')\nprint(f'calfire dataset geometry:\\n {calfire.geometry.head()}')\n\n# visualize calfire data\ncalfire.plot(color = 'none')\n\n\ncalfire dataset shape: (608, 23)\ncalfire dataset crs: epsg:3857\ncalfire dataset geometry:\n 0    POLYGON ((-13229812.974 4046876.486, -13229786...\n1    POLYGON ((-13286872.985 4074523.355, -13286895...\n2    POLYGON ((-13244637.580 4056332.530, -13244620...\n3    POLYGON ((-13229521.754 4046254.111, -13229510...\n4    POLYGON ((-13229663.036 4046858.853, -13229667...\nName: geometry, dtype: geometry\n\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\nCalifornia fire perimeter dataset includes the list of all fires in California during 2017. For our analysis, we are interested only in Thomas fire that occured that year.\nTherefore, we need to filter the dataset to the rows with Thomas fire.\n\n\nCode\n# update the column names case to snake_case\ncalfire.columns = calfire.columns.str.lower().str.replace(' ','_')\nprint(calfire.columns)\n\n# find the value that corresponds to Thomas fire\ncalfire[calfire.fire_name.str.contains('Thomas', case=False, na=False)]['fire_name'].unique()\n\n\nIndex(['index', 'objectid', 'year_', 'state', 'agency', 'unit_id', 'fire_name',\n       'inc_num', 'alarm_date', 'cont_date', 'cause', 'c_method', 'objective',\n       'gis_acres', 'comments', 'complex_na', 'complex_in', 'irwinid',\n       'fire_num', 'decades', 'shape_leng', 'shape_area', 'geometry'],\n      dtype='object')\n\n\narray(['THOMAS'], dtype=object)\n\n\nWe only have one record with fire_name = THOMAS. This is the record that we want to use for our analysis.\n\n\nCode\n# create a new dataframe with Thomas fire details\ntf = calfire[calfire.fire_name == 'THOMAS']\n\n\n\n\nCode\n# explore data of the netCDF file\n\nprint(f'lsat CRS: {lsat.rio.crs}')\n\n# print shape and data type\nprint('shape: ', lsat.rio.shape)\nprint('data type: ', type(lsat), '\\n')\n# print(lsat)\n\n# make a simple map to visualize lsat dataset\nlsat['red'].plot()\n\n\nlsat CRS: EPSG:32611\nshape:  (731, 870)\ndata type:  &lt;class 'xarray.core.dataset.Dataset'&gt; \n\n\n\n&lt;matplotlib.collections.QuadMesh at 0x7f786aef5ee0&gt;\n\n\n\n\n\n⚠️ Notice the following two details:\n\nThe Coordinate Reference Systems (CRS) of the two datasets are different. Since we want to overlay the Thomas Fire perimeter on the Santa Barbara County land cover, we need to ensure that the CRSs of the two datasets are the same. To achieve this, we will reproject the CRS of the tf dataset into the CRS of the lsat dataset.\nThe lsat dataset includes an additional dimension, the band, which makes it a 3-dimensional object. We are going to convert it into a 2-dimensional dataset by dropping the band dimension.\n\n\n\nCode\n# drop an extra dimension \"band\" from lsat dataset\nlsat = lsat.squeeze().drop('band')\n\n# check that band dimension has been dropped\nprint(f'After squeeze:\\ndimensions {lsat.dims}\\ncoords: {lsat.coords}')\n\n# update CRS of the shape file to lsat CRS\ntf = tf.to_crs(crs = lsat.rio.crs)\n\n# check that CRS of the two datasets match\nprint(f'CRS of the lsat and tf datasets match: {tf.crs == lsat.rio.crs}')\n\n\nAfter squeeze:\ndimensions Frozen({'y': 731, 'x': 870})\ncoords: Coordinates:\n  * y            (y) float64 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n  * x            (x) float64 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n    spatial_ref  int64 0\nCRS of the lsat and tf datasets match: True\n\n\n\n\n\nIn the final step we will create a map showing the shortwave infrared/nir/ ed false color image together with the Thomas fire perimeter.\n\n\nCode\nfig, ax = plt.subplots()\n\n# remove axis\nax.axis('off')\n\n# plot Thomas fire perimeter\ntf.plot(ax=ax, color='none', edgecolor = '#483C32')\ntf_patch = mpatches.Patch(facecolor = 'none', \n                          edgecolor='#483C32', \n                          label='Thomas Fire Perimeter (2017)')\n\n# plot raster image of Santa Barbara area\nlsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(ax=ax, robust = True)\n\n# add legend\nax.legend(handles=[tf_patch], frameon=True, loc='upper right')\nax.set_title('Thomas Fire (Santa Barbara, 2017)')\n\n# annotate the data source\nax.annotate(\"Data: Microsoft Planetary Computer.https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed 28 Nov. 2023.\\nCalifornia Fire Perimeters (All).https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about. Accessed 28 Nov. 2023.\",\n            xy=(0.5, -0.15),  # Move the annotation lower to leave space for the x-axis title\n            fontsize=7, \n            xycoords='axes fraction',  \n            color='#555555',\n            ha='center')  \n\n# adjust the botton space of the figure\nplt.subplots_adjust(bottom=0.01)\n\n# display map\nplt.show()"
  },
  {
    "objectID": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#overview",
    "href": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#overview",
    "title": "Impact of the Thomas Fire on AQI in Santa Barbara County, CA (2017)",
    "section": "",
    "text": "In this notebook, we are going to analyze the impact of Thomas Fire on the air quality in Santa Barbara county in 2017. To do so, we will complete the following two tasks: 1. Visualize the Air Quality Index (AQI) in Santa Barbara County for 2017 and 2018. 2. Create a map to visualize the Thomas Fire scar.\n\n\nThe primary purpose of the notebook is to demonstrate environmental data analysis methods using both vector and raster data.\n\n\n\n\nPython libraries\n\nnumpy\npandas\npyplot and patches from matplotlib\nrioxarray\ngeopandas\nxarray\n\nJupyter Notebook\nGitHub\n\n\n\n\n\nData wrangling and exploration with Pandas\nGeospatial data wrangling with GeoPandas and Rioxarray\nTime series analysis\nMerging tabular and vector data\nVisualizing analysis results with a line plot\nCreating and customizing a map with raster and vector data\n\n\n\n\n\n\nAir Quality Index (AQI) data from the US Environmental Protection Agency[1] to visualize the impact on the AQI of the 2017 Thomas Fire in Santa Barbara County [2].\n\n\n\nA simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite [3]. Note: data should be used for visualization purposes only.\nInformation about Landsat bands from USGS:\n\nWhat are the band designations for the Landsat satellites?\nCommon Landsat Band Combinations\nHow do I use a scale factor with Landsat Level-2 science products?\n\n\n\n\nA prepared shapefile of fire perimeters in California during 2017. The complete file can be accessed in the CA state geoportal[4].\nData for datasets 2 and 3 is available on Google Drive in the file thomasfire_aqi_analysis.zip."
  },
  {
    "objectID": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#final-output",
    "href": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#final-output",
    "title": "Impact of the Thomas Fire on AQI in Santa Barbara County, CA (2017)",
    "section": "",
    "text": "The final outputs of the analysis include:\n\nA Line Plot depicting the time series analysis of the Air Quality Index (AQI) in Santa Barbara for 2017 and 2018. \nA Map with an overlay of the Thomas Fire scar on the Santa Barbara land cover. \n\n\n\n[1] AirData Website File Download Page. https://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI. Accessed 28 Nov. 2023. [2] “Thomas Fire.” Wikipedia, 9 Nov. 2023. Wikipedia, https://en.wikipedia.org/w/index.php?title=Thomas_Fire&oldid=1184323284. [3] Microsoft Planetary Computer. https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed 28 Nov. 2023. [4] California Fire Perimeters (All). https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about. Accessed 28 Nov. 2023."
  },
  {
    "objectID": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#import-libraries",
    "href": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#import-libraries",
    "title": "Impact of the Thomas Fire on AQI in Santa Barbara County, CA (2017)",
    "section": "",
    "text": "Code\n# import libraries with standard abbreviations\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches # for creating legends\n\nimport rioxarray as rioxr\nimport geopandas as gpd\nimport xarray as xr"
  },
  {
    "objectID": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#import-data",
    "href": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#import-data",
    "title": "Impact of the Thomas Fire on AQI in Santa Barbara County, CA (2017)",
    "section": "",
    "text": "Code\n# import Daily AQI by County data from url: Dataset 1\n# read in 2017 Daily AQI by County\nurl_aqi_17 = 'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip'\naqi_17 = pd.read_csv(url_aqi_17)\n\n# read in 2018 Daily AQI by County\nurl_aqi_18 = 'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip'\naqi_18 = pd.read_csv(url_aqi_18)\n\n\n\n\n\n\n\nCode\n# use rioxarray library to import netCDF file with geospatial features\nfp_lsat = 'data/landsat8-2018-01-26-sb-simplified.nc'\nlsat = rioxr.open_rasterio(fp_lsat)\n\n\n\n\n\n\n\nCode\n# use geopandas to import shape file with California fire perimeters \ncalfire = gpd.read_file(os.path.join(os.getcwd(), 'data', \n                                     'California_Fire_Perimeters_2017',\n                                     'California_Fire_Perimeters_2017.shp'))"
  },
  {
    "objectID": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#prepare-air-quality-data",
    "href": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#prepare-air-quality-data",
    "title": "Impact of the Thomas Fire on AQI in Santa Barbara County, CA (2017)",
    "section": "",
    "text": "Let’s take a quick look at the data before we proceed with data wrangling steps.\n\n\nCode\n# view the list of columns \nprint(aqi_17.columns)\n\n# view the first 2 rows of the dataframe aqi_17\naqi_17.head(2)\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object')\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n21\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n\nCode\n# view the list of columns \nprint(aqi_18.columns)\n\n# view the first 2 rows of the dataframe aqi_18\naqi_18.head(2)\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object')\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2018-01-02\n32\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2018-01-05\n34\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\nNotice that we currently have two separate dataframes. However, in order to analyze AQI for the two years, we need to combine them by appending the rows from one dataframe on top of the other. We will use the pandas function pd.concat() to do so.\nImportant: the columns of the two datasets have to match.\n\n\nCode\n# check whether the columns between the two datasets match\nprint(f'Do columns match?\\n {aqi_18.columns == aqi_17.columns} \\n')\n\n# check whether the column datatypes between the two datasets match\nprint(f'Do datatypes of the columns match?\\n{aqi_18.dtypes == aqi_17.dtypes}')\n\n\nDo columns match?\n [ True  True  True  True  True  True  True  True  True  True] \n\nDo datatypes of the columns match?\nState Name                   True\ncounty Name                  True\nState Code                   True\nCounty Code                  True\nDate                         True\nAQI                          True\nCategory                     True\nDefining Parameter           True\nDefining Site                True\nNumber of Sites Reporting    True\ndtype: bool\n\n\nNote: since the column names and datatypes of the two datasets match exaclty we can combine the them into a single dataframe. Let’s check how many records we should expect in the combined dataframe.\n\n\nCode\n# get the count of rows that have state = CA and county = Santa Barbara in the dataframe aqi_17\naqi_17_count = len(aqi_17)\n\n# get the count of rows that have state = CA and county = Santa Barbara in the dataframe aqi_18\naqi_18_count = len(aqi_18)\n\n# get the total count of rows we expect in the combined dataframe\ntot_count = aqi_17_count + aqi_18_count\nprint(f'Combined dataframe should have total number of rows: {tot_count}')  \n\n\nCombined dataframe should have total number of rows: 654338\n\n\n\n\nCode\n# combine two datasets aqi_17 and aqi_18 in a single one\naqi = pd.concat([aqi_17, aqi_18])\n\n# check the total count of rows matches the expected number\naqi_count = len(aqi)\nprint(f'Count of rows in the combined aqi dataframe: {aqi_count}')\nprint(f'Is the total number of rows in the combined dataframe as expected? {aqi_count == tot_count} \\n')\n\n# check the first 2 rows of the combined dataframe\naqi.head(2)\n\n\nCount of rows in the combined aqi dataframe: 654338\nIs the total number of rows in the combined dataframe as expected? True \n\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n21\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\nNotice that column names have inconsistent case and spaces in between the words. Let’s update the column names to snake_case 🐍 to simplify data manipulation.\n\n\nCode\n# update the column names case to snake_case\naqi.columns = aqi.columns.str.lower().str.replace(' ','_')\n# check that the column names are updated\nprint(aqi.columns)\n\n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object')\n\n\nFor our analysis we need only AQI data from the Santa Barbara county. Let’s create a new dataframeaqi_sb filtered to Santa Barbara county. Additionally, we can remove unecessary columns state_name, county_name, state_code and county_code from the new dataframe.\n\n\nCode\n# select the records where county_name = 'Santa Barbara' from the combined dataset aqi\naqi_sb = aqi.loc[aqi.county_name == 'Santa Barbara'].copy()\n\n# remove the state_name, county_name, state_code and county_code columns from aqi_sb\naqi_sb = aqi_sb.drop(columns = ['state_name', 'county_name', 'state_code', 'county_code'])\n\n\n\n\nCode\n# check the data types of the columns\nprint(aqi_sb.dtypes)\n\n\ndate                         object\naqi                           int64\ncategory                     object\ndefining_parameter           object\ndefining_site                object\nnumber_of_sites_reporting     int64\ndtype: object\n\n\n⚠️ Date column has type object rather than datetime as expected.\nWe will make the following changes to facilitate working with dates:\n\nConvert the date column of aqi_sb to a datetime object.\nSet the date column as the index for aqi_sb dataframe.\n\n\n\nCode\n# update date column values of aqi_sb to datetype object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n      \n# update the index of aqi_sb to be the date column\naqi_sb = aqi_sb.set_index('date')\n\n# check column date is updated\nprint(aqi_sb.index)\n\n\nDatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03', '2017-01-04',\n               '2017-01-05', '2017-01-06', '2017-01-07', '2017-01-08',\n               '2017-01-09', '2017-01-10',\n               ...\n               '2018-12-22', '2018-12-23', '2018-12-24', '2018-12-25',\n               '2018-12-26', '2018-12-27', '2018-12-28', '2018-12-29',\n               '2018-12-30', '2018-12-31'],\n              dtype='datetime64[ns]', name='date', length=730, freq=None)\n\n\nOur current dataframe contains daily values of AQI, which can create short-term fluctuations and noise in data. We’ll apply a 5-day rolling average to smooth out the data and improve the quality of the analysis. To achieve this we will create a new variable, five_day_average, using the pandas method rolling.\nNote: rolling() is a method for pandas.series that provides rolling window calculations. This is a lazy method (think groupby), we need to specify what we want to calculate over each window. It returns pd.Series as ouput.\n\n\nCode\n# calculate 5-day rolling average AQI\n# the parameter '5D' indicates we want the window to be 5 days\naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean() \n\n# view the first two rows of the updated dataframe\naqi_sb.head(2)\n\n\n\n\n\n\n\n\n\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\nfive_day_average\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n2017-01-01\n39\nGood\nOzone\n06-083-4003\n12\n39.0\n\n\n2017-01-02\n36\nGood\nOzone\n06-083-4003\n11\n37.5"
  },
  {
    "objectID": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#visualize-aqi-output",
    "href": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#visualize-aqi-output",
    "title": "Impact of the Thomas Fire on AQI in Santa Barbara County, CA (2017)",
    "section": "",
    "text": "In the next step, we will create a line plot with daily AQI and 5-day average AQI to visualize the impact of the Thomas Fire (December 2017) on air quality in Santa Barbara County.\n\n\nCode\n# plot both the daily AQI and the 5-day average\nfig, ax = plt.subplots()\n\naqi_sb.aqi.plot(ax=ax,\n                color = '#fecc5c')\naqi_sb.five_day_average.plot(ax=ax,\n                color = '#a50f15')\n\n# update axis\nax.set_title('Daily Average vs 5 day Average AQI in Santa Barbara (2017-2018)')\nax.set_xlabel('Period')\nax.set_ylabel('AQI')\nax.legend(['AQI Daily Average', 'AQI 5-day Average'])\n\n# annotate the data source\nax.annotate(\"Data: AirData Website File Download Page.\\nhttps://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI. Accessed 28 Nov. 2023\",\n            xy=(0.5, -0.15), \n            fontsize=7, \n            xycoords='axes fraction',  \n            color='#555555',\n            ha='center',\n            va='top')  \n\n# adjust the botton space of the figure\nplt.subplots_adjust(bottom=0.01)\n\nplt.show\n\n\n&lt;function matplotlib.pyplot.show(close=None, block=None)&gt;\n\n\n\n\n\nFrom the graph we can see a significant increase in both the daily average and 5-day rolling average in December 2017 compared to the rest of the year, which coincides with the Thomas Fire event. During this period, the AQI exceeded 200, falling into the very unhealthy category. According to AQI standards, at this level, the risk of health effects is increased for everyone."
  },
  {
    "objectID": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#prepare-geospatial-data",
    "href": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#prepare-geospatial-data",
    "title": "Impact of the Thomas Fire on AQI in Santa Barbara County, CA (2017)",
    "section": "",
    "text": "First, let’s inspect geospatial datasets.\n\n\nCode\n# view the first two records of imported shape file data\ncalfire.head(2)\n\n\n\n\n\n\n\n\n\nindex\nOBJECTID\nYEAR_\nSTATE\nAGENCY\nUNIT_ID\nFIRE_NAME\nINC_NUM\nALARM_DATE\nCONT_DATE\n...\nGIS_ACRES\nCOMMENTS\nCOMPLEX_NA\nCOMPLEX_IN\nIRWINID\nFIRE_NUM\nDECADES\nSHAPE_Leng\nSHAPE_Area\ngeometry\n\n\n\n\n0\n19836\n41429\n2017\nCA\nCCO\nVNC\nBROOK\n00042450\n2017-05-23\n2017-05-24\n...\n10.043819\nper walked track\nNone\nNone\nNone\nNone\n2010\n1246.055781\n59473.666651\nPOLYGON ((-13229812.974 4046876.486, -13229786...\n\n\n1\n19837\n41430\n2017\nCA\nCCO\nVNC\nPACIFIC\n00075307\n2017-09-09\n2017-09-09\n...\n1.190109\nFinal Walked track. Small spot to the north east\nNone\nNone\nNone\nNone\n2010\n561.418202\n7081.369481\nPOLYGON ((-13286872.985 4074523.355, -13286895...\n\n\n\n\n2 rows × 23 columns\n\n\n\n\n\nCode\nprint(f'calfire dataset shape: {calfire.shape}')\nprint(f'calfire dataset crs: {calfire.crs}')\nprint(f'calfire dataset geometry:\\n {calfire.geometry.head()}')\n\n# visualize calfire data\ncalfire.plot(color = 'none')\n\n\ncalfire dataset shape: (608, 23)\ncalfire dataset crs: epsg:3857\ncalfire dataset geometry:\n 0    POLYGON ((-13229812.974 4046876.486, -13229786...\n1    POLYGON ((-13286872.985 4074523.355, -13286895...\n2    POLYGON ((-13244637.580 4056332.530, -13244620...\n3    POLYGON ((-13229521.754 4046254.111, -13229510...\n4    POLYGON ((-13229663.036 4046858.853, -13229667...\nName: geometry, dtype: geometry\n\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\nCalifornia fire perimeter dataset includes the list of all fires in California during 2017. For our analysis, we are interested only in Thomas fire that occured that year.\nTherefore, we need to filter the dataset to the rows with Thomas fire.\n\n\nCode\n# update the column names case to snake_case\ncalfire.columns = calfire.columns.str.lower().str.replace(' ','_')\nprint(calfire.columns)\n\n# find the value that corresponds to Thomas fire\ncalfire[calfire.fire_name.str.contains('Thomas', case=False, na=False)]['fire_name'].unique()\n\n\nIndex(['index', 'objectid', 'year_', 'state', 'agency', 'unit_id', 'fire_name',\n       'inc_num', 'alarm_date', 'cont_date', 'cause', 'c_method', 'objective',\n       'gis_acres', 'comments', 'complex_na', 'complex_in', 'irwinid',\n       'fire_num', 'decades', 'shape_leng', 'shape_area', 'geometry'],\n      dtype='object')\n\n\narray(['THOMAS'], dtype=object)\n\n\nWe only have one record with fire_name = THOMAS. This is the record that we want to use for our analysis.\n\n\nCode\n# create a new dataframe with Thomas fire details\ntf = calfire[calfire.fire_name == 'THOMAS']\n\n\n\n\nCode\n# explore data of the netCDF file\n\nprint(f'lsat CRS: {lsat.rio.crs}')\n\n# print shape and data type\nprint('shape: ', lsat.rio.shape)\nprint('data type: ', type(lsat), '\\n')\n# print(lsat)\n\n# make a simple map to visualize lsat dataset\nlsat['red'].plot()\n\n\nlsat CRS: EPSG:32611\nshape:  (731, 870)\ndata type:  &lt;class 'xarray.core.dataset.Dataset'&gt; \n\n\n\n&lt;matplotlib.collections.QuadMesh at 0x7f786aef5ee0&gt;\n\n\n\n\n\n⚠️ Notice the following two details:\n\nThe Coordinate Reference Systems (CRS) of the two datasets are different. Since we want to overlay the Thomas Fire perimeter on the Santa Barbara County land cover, we need to ensure that the CRSs of the two datasets are the same. To achieve this, we will reproject the CRS of the tf dataset into the CRS of the lsat dataset.\nThe lsat dataset includes an additional dimension, the band, which makes it a 3-dimensional object. We are going to convert it into a 2-dimensional dataset by dropping the band dimension.\n\n\n\nCode\n# drop an extra dimension \"band\" from lsat dataset\nlsat = lsat.squeeze().drop('band')\n\n# check that band dimension has been dropped\nprint(f'After squeeze:\\ndimensions {lsat.dims}\\ncoords: {lsat.coords}')\n\n# update CRS of the shape file to lsat CRS\ntf = tf.to_crs(crs = lsat.rio.crs)\n\n# check that CRS of the two datasets match\nprint(f'CRS of the lsat and tf datasets match: {tf.crs == lsat.rio.crs}')\n\n\nAfter squeeze:\ndimensions Frozen({'y': 731, 'x': 870})\ncoords: Coordinates:\n  * y            (y) float64 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n  * x            (x) float64 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n    spatial_ref  int64 0\nCRS of the lsat and tf datasets match: True"
  },
  {
    "objectID": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#create-a-map",
    "href": "posts/2023-12-12-thomas-fire/thomasfire_aqi_analysis.html#create-a-map",
    "title": "Impact of the Thomas Fire on AQI in Santa Barbara County, CA (2017)",
    "section": "",
    "text": "In the final step we will create a map showing the shortwave infrared/nir/ ed false color image together with the Thomas fire perimeter.\n\n\nCode\nfig, ax = plt.subplots()\n\n# remove axis\nax.axis('off')\n\n# plot Thomas fire perimeter\ntf.plot(ax=ax, color='none', edgecolor = '#483C32')\ntf_patch = mpatches.Patch(facecolor = 'none', \n                          edgecolor='#483C32', \n                          label='Thomas Fire Perimeter (2017)')\n\n# plot raster image of Santa Barbara area\nlsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(ax=ax, robust = True)\n\n# add legend\nax.legend(handles=[tf_patch], frameon=True, loc='upper right')\nax.set_title('Thomas Fire (Santa Barbara, 2017)')\n\n# annotate the data source\nax.annotate(\"Data: Microsoft Planetary Computer.https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed 28 Nov. 2023.\\nCalifornia Fire Perimeters (All).https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about. Accessed 28 Nov. 2023.\",\n            xy=(0.5, -0.15),  # Move the annotation lower to leave space for the x-axis title\n            fontsize=7, \n            xycoords='axes fraction',  \n            color='#555555',\n            ha='center')  \n\n# adjust the botton space of the figure\nplt.subplots_adjust(bottom=0.01)\n\n# display map\nplt.show()"
  },
  {
    "objectID": "posts/thomas-fire/thomasfire_aqi_analysis2.html",
    "href": "posts/thomas-fire/thomasfire_aqi_analysis2.html",
    "title": "thomas fire analysis",
    "section": "",
    "text": "Author: Oksana Protsukha\nGithub repository: https://github.com/oksanaprotsukha/thomasfire_aqi_analysis\n\n\nIn this notebook, we are going to analyze the impact of Thomas Fire on the air quality in Santa Barbara county in 2017. To do so, we will complete the following two tasks: 1. Visualize the Air Quality Index (AQI) in Santa Barbara County for 2017 and 2018. 2. Create a map to visualize the Thomas Fire scar.\n\n\nThe primary purpose of the notebook is to demonstrate environmental data analysis methods using both vector and raster data.\n\n\n\n\nPython libraries\n\nnumpy\npandas\npyplot and patches from matplotlib\nrioxarray\ngeopandas\nxarray\n\nJupyter Notebook\nGitHub\n\n\n\n\n\nData wrangling and exploration with Pandas\nGeospatial data wrangling with GeoPandas and Rioxarray\nTime series analysis\nMerging tabular and vector data\nVisualizing analysis results with a line plot\nCreating and customizing a map with raster and vector data\n\n\n\n\n\n\nAir Quality Index (AQI) data from the US Environmental Protection Agency[1] to visualize the impact on the AQI of the 2017 Thomas Fire in Santa Barbara County [2].\n\n\n\nA simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite [3]. Note: data should be used for visualization purposes only.\nInformation about Landsat bands from USGS:\n\nWhat are the band designations for the Landsat satellites?\nCommon Landsat Band Combinations\nHow do I use a scale factor with Landsat Level-2 science products?\n\n\n\n\nA prepared shapefile of fire perimeters in California during 2017. The complete file can be accessed in the CA state geoportal[4].\nData for datasets 2 and 3 is available on Google Drive in the file thomasfire_aqi_analysis.zip.\n\n\n\n\n\nThe final outputs of the analysis include:\n\nA Line Plot depicting the time series analysis of the Air Quality Index (AQI) in Santa Barbara for 2017 and 2018. \nA Map with an overlay of the Thomas Fire scar on the Santa Barbara land cover. \n\n\n\n[1] AirData Website File Download Page. https://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI. Accessed 28 Nov. 2023. [2] “Thomas Fire.” Wikipedia, 9 Nov. 2023. Wikipedia, https://en.wikipedia.org/w/index.php?title=Thomas_Fire&oldid=1184323284. [3] Microsoft Planetary Computer. https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed 28 Nov. 2023. [4] California Fire Perimeters (All). https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about. Accessed 28 Nov. 2023.\n\n\n\n\n\n\nCode\n# import libraries with standard abbreviations\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches # for creating legends\n\nimport rioxarray as rioxr\nimport geopandas as gpd\nimport xarray as xr\n\n\n\n\n\n\n\n\n\nCode\n# import Daily AQI by County data from url: Dataset 1\n# read in 2017 Daily AQI by County\nurl_aqi_17 = 'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip'\naqi_17 = pd.read_csv(url_aqi_17)\n\n# read in 2018 Daily AQI by County\nurl_aqi_18 = 'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip'\naqi_18 = pd.read_csv(url_aqi_18)\n\n\n\n\n\n\n\nCode\n# use rioxarray library to import netCDF file with geospatial features\nfp_lsat = 'data/landsat8-2018-01-26-sb-simplified.nc'\nlsat = rioxr.open_rasterio(fp_lsat)\n\n\n\n\n\n\n\nCode\n# use geopandas to import shape file with California fire perimeters \ncalfire = gpd.read_file(os.path.join(os.getcwd(), 'data', \n                                     'California_Fire_Perimeters_2017',\n                                     'California_Fire_Perimeters_2017.shp'))  \n\n\n\n\n\n\nLet’s take a quick look at the data before we proceed with data wrangling steps.\n\n\nCode\n# view the list of columns \nprint(aqi_17.columns)\n\n# view the first 2 rows of the dataframe aqi_17\naqi_17.head(2)\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object')\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n21\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n\nCode\n# view the list of columns \nprint(aqi_18.columns)\n\n# view the first 2 rows of the dataframe aqi_18\naqi_18.head(2)\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object')\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2018-01-02\n32\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2018-01-05\n34\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\nNotice that we currently have two separate dataframes. However, in order to analyze AQI for the two years, we need to combine them by appending the rows from one dataframe on top of the other. We will use the pandas function pd.concat() to do so.\nImportant: the columns of the two datasets have to match.\n\n\nCode\n# check whether the columns between the two datasets match\nprint(f'Do columns match?\\n {aqi_18.columns == aqi_17.columns} \\n')\n\n# check whether the column datatypes between the two datasets match\nprint(f'Do datatypes of the columns match?\\n{aqi_18.dtypes == aqi_17.dtypes}')\n\n\nDo columns match?\n [ True  True  True  True  True  True  True  True  True  True] \n\nDo datatypes of the columns match?\nState Name                   True\ncounty Name                  True\nState Code                   True\nCounty Code                  True\nDate                         True\nAQI                          True\nCategory                     True\nDefining Parameter           True\nDefining Site                True\nNumber of Sites Reporting    True\ndtype: bool\n\n\nNote: since the column names and datatypes of the two datasets match exaclty we can combine the them into a single dataframe. Let’s check how many records we should expect in the combined dataframe.\n\n\nCode\n# get the count of rows that have state = CA and county = Santa Barbara in the dataframe aqi_17\naqi_17_count = len(aqi_17)\n\n# get the count of rows that have state = CA and county = Santa Barbara in the dataframe aqi_18\naqi_18_count = len(aqi_18)\n\n# get the total count of rows we expect in the combined dataframe\ntot_count = aqi_17_count + aqi_18_count\nprint(f'Combined dataframe should have total number of rows: {tot_count}')  \n\n\nCombined dataframe should have total number of rows: 654338\n\n\n\n\nCode\n# combine two datasets aqi_17 and aqi_18 in a single one\naqi = pd.concat([aqi_17, aqi_18])\n\n# check the total count of rows matches the expected number\naqi_count = len(aqi)\nprint(f'Count of rows in the combined aqi dataframe: {aqi_count}')\nprint(f'Is the total number of rows in the combined dataframe as expected? {aqi_count == tot_count} \\n')\n\n# check the first 2 rows of the combined dataframe\naqi.head(2)\n\n\nCount of rows in the combined aqi dataframe: 654338\nIs the total number of rows in the combined dataframe as expected? True \n\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n21\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\nNotice that column names have inconsistent case and spaces in between the words. Let’s update the column names to snake_case 🐍 to simplify data manipulation.\n\n\nCode\n# update the column names case to snake_case\naqi.columns = aqi.columns.str.lower().str.replace(' ','_')\n# check that the column names are updated\nprint(aqi.columns)\n\n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object')\n\n\nFor our analysis we need only AQI data from the Santa Barbara county. Let’s create a new dataframeaqi_sb filtered to Santa Barbara county. Additionally, we can remove unecessary columns state_name, county_name, state_code and county_code from the new dataframe.\n\n\nCode\n# select the records where county_name = 'Santa Barbara' from the combined dataset aqi\naqi_sb = aqi.loc[aqi.county_name == 'Santa Barbara'].copy()\n\n# remove the state_name, county_name, state_code and county_code columns from aqi_sb\naqi_sb = aqi_sb.drop(columns = ['state_name', 'county_name', 'state_code', 'county_code'])\n\n\n\n\nCode\n# check the data types of the columns\nprint(aqi_sb.dtypes)\n\n\ndate                         object\naqi                           int64\ncategory                     object\ndefining_parameter           object\ndefining_site                object\nnumber_of_sites_reporting     int64\ndtype: object\n\n\n⚠️ Date column has type object rather than datetime as expected.\nWe will make the following changes to facilitate working with dates:\n\nConvert the date column of aqi_sb to a datetime object.\nSet the date column as the index for aqi_sb dataframe.\n\n\n\nCode\n# update date column values of aqi_sb to datetype object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n      \n# update the index of aqi_sb to be the date column\naqi_sb = aqi_sb.set_index('date')\n\n# check column date is updated\nprint(aqi_sb.index)\n\n\nDatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03', '2017-01-04',\n               '2017-01-05', '2017-01-06', '2017-01-07', '2017-01-08',\n               '2017-01-09', '2017-01-10',\n               ...\n               '2018-12-22', '2018-12-23', '2018-12-24', '2018-12-25',\n               '2018-12-26', '2018-12-27', '2018-12-28', '2018-12-29',\n               '2018-12-30', '2018-12-31'],\n              dtype='datetime64[ns]', name='date', length=730, freq=None)\n\n\nOur current dataframe contains daily values of AQI, which can create short-term fluctuations and noise in data. We’ll apply a 5-day rolling average to smooth out the data and improve the quality of the analysis. To achieve this we will create a new variable, five_day_average, using the pandas method rolling.\nNote: rolling() is a method for pandas.series that provides rolling window calculations. This is a lazy method (think groupby), we need to specify what we want to calculate over each window. It returns pd.Series as ouput.\n\n\nCode\n# calculate 5-day rolling average AQI\n# the parameter '5D' indicates we want the window to be 5 days\naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean() \n\n# view the first two rows of the updated dataframe\naqi_sb.head(2)\n\n\n\n\n\n\n\n\n\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\nfive_day_average\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n2017-01-01\n39\nGood\nOzone\n06-083-4003\n12\n39.0\n\n\n2017-01-02\n36\nGood\nOzone\n06-083-4003\n11\n37.5\n\n\n\n\n\n\n\n\n\n\nIn the next step, we will create a line plot with daily AQI and 5-day average AQI to visualize the impact of the Thomas Fire (December 2017) on air quality in Santa Barbara County.\n\n\nCode\n# plot both the daily AQI and the 5-day average\nfig, ax = plt.subplots()\n\naqi_sb.aqi.plot(ax=ax,\n                color = '#fecc5c')\naqi_sb.five_day_average.plot(ax=ax,\n                color = '#a50f15')\n\n# update axis\nax.set_title('Daily Average vs 5 day Average AQI in Santa Barbara (2017-2018)')\nax.set_xlabel('Period')\nax.set_ylabel('AQI')\nax.legend(['AQI Daily Average', 'AQI 5-day Average'])\n\n# annotate the data source\nax.annotate(\"Data: AirData Website File Download Page.\\nhttps://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI. Accessed 28 Nov. 2023\",\n            xy=(0.5, -0.15), \n            fontsize=7, \n            xycoords='axes fraction',  \n            color='#555555',\n            ha='center',\n            va='top')  \n\n# adjust the botton space of the figure\nplt.subplots_adjust(bottom=0.01)\n\nplt.show\n\n\n&lt;function matplotlib.pyplot.show(close=None, block=None)&gt;\n\n\n\n\n\nFrom the graph we can see a significant increase in both the daily average and 5-day rolling average in December 2017 compared to the rest of the year, which coincides with the Thomas Fire event. During this period, the AQI exceeded 200, falling into the very unhealthy category. According to AQI standards, at this level, the risk of health effects is increased for everyone.\n\n\n\nFirst, let’s inspect geospatial datasets.\n\n\nCode\n# view the first two records of imported shape file data\ncalfire.head(2)\n\n\n\n\n\n\n\n\n\nindex\nOBJECTID\nYEAR_\nSTATE\nAGENCY\nUNIT_ID\nFIRE_NAME\nINC_NUM\nALARM_DATE\nCONT_DATE\n...\nGIS_ACRES\nCOMMENTS\nCOMPLEX_NA\nCOMPLEX_IN\nIRWINID\nFIRE_NUM\nDECADES\nSHAPE_Leng\nSHAPE_Area\ngeometry\n\n\n\n\n0\n19836\n41429\n2017\nCA\nCCO\nVNC\nBROOK\n00042450\n2017-05-23\n2017-05-24\n...\n10.043819\nper walked track\nNone\nNone\nNone\nNone\n2010\n1246.055781\n59473.666651\nPOLYGON ((-13229812.974 4046876.486, -13229786...\n\n\n1\n19837\n41430\n2017\nCA\nCCO\nVNC\nPACIFIC\n00075307\n2017-09-09\n2017-09-09\n...\n1.190109\nFinal Walked track. Small spot to the north east\nNone\nNone\nNone\nNone\n2010\n561.418202\n7081.369481\nPOLYGON ((-13286872.985 4074523.355, -13286895...\n\n\n\n\n2 rows × 23 columns\n\n\n\n\n\nCode\nprint(f'calfire dataset shape: {calfire.shape}')\nprint(f'calfire dataset crs: {calfire.crs}')\nprint(f'calfire dataset geometry:\\n {calfire.geometry.head()}')\n\n# visualize calfire data\ncalfire.plot(color = 'none')\n\n\ncalfire dataset shape: (608, 23)\ncalfire dataset crs: epsg:3857\ncalfire dataset geometry:\n 0    POLYGON ((-13229812.974 4046876.486, -13229786...\n1    POLYGON ((-13286872.985 4074523.355, -13286895...\n2    POLYGON ((-13244637.580 4056332.530, -13244620...\n3    POLYGON ((-13229521.754 4046254.111, -13229510...\n4    POLYGON ((-13229663.036 4046858.853, -13229667...\nName: geometry, dtype: geometry\n\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\nCalifornia fire perimeter dataset includes the list of all fires in California during 2017. For our analysis, we are interested only in Thomas fire that occured that year.\nTherefore, we need to filter the dataset to the rows with Thomas fire.\n\n\nCode\n# update the column names case to snake_case\ncalfire.columns = calfire.columns.str.lower().str.replace(' ','_')\nprint(calfire.columns)\n\n# find the value that corresponds to Thomas fire\ncalfire[calfire.fire_name.str.contains('Thomas', case=False, na=False)]['fire_name'].unique()\n\n\nIndex(['index', 'objectid', 'year_', 'state', 'agency', 'unit_id', 'fire_name',\n       'inc_num', 'alarm_date', 'cont_date', 'cause', 'c_method', 'objective',\n       'gis_acres', 'comments', 'complex_na', 'complex_in', 'irwinid',\n       'fire_num', 'decades', 'shape_leng', 'shape_area', 'geometry'],\n      dtype='object')\n\n\narray(['THOMAS'], dtype=object)\n\n\nWe only have one record with fire_name = THOMAS. This is the record that we want to use for our analysis.\n\n\nCode\n# create a new dataframe with Thomas fire details\ntf = calfire[calfire.fire_name == 'THOMAS']\n\n\n\n\nCode\n# explore data of the netCDF file\n\nprint(f'lsat CRS: {lsat.rio.crs}')\n\n# print shape and data type\nprint('shape: ', lsat.rio.shape)\nprint('data type: ', type(lsat), '\\n')\n# print(lsat)\n\n# make a simple map to visualize lsat dataset\nlsat['red'].plot()\n\n\nlsat CRS: EPSG:32611\nshape:  (731, 870)\ndata type:  &lt;class 'xarray.core.dataset.Dataset'&gt; \n\n\n\n&lt;matplotlib.collections.QuadMesh at 0x7f786aef5ee0&gt;\n\n\n\n\n\n⚠️ Notice the following two details:\n\nThe Coordinate Reference Systems (CRS) of the two datasets are different. Since we want to overlay the Thomas Fire perimeter on the Santa Barbara County land cover, we need to ensure that the CRSs of the two datasets are the same. To achieve this, we will reproject the CRS of the tf dataset into the CRS of the lsat dataset.\nThe lsat dataset includes an additional dimension, the band, which makes it a 3-dimensional object. We are going to convert it into a 2-dimensional dataset by dropping the band dimension.\n\n\n\nCode\n# drop an extra dimension \"band\" from lsat dataset\nlsat = lsat.squeeze().drop('band')\n\n# check that band dimension has been dropped\nprint(f'After squeeze:\\ndimensions {lsat.dims}\\ncoords: {lsat.coords}')\n\n# update CRS of the shape file to lsat CRS\ntf = tf.to_crs(crs = lsat.rio.crs)\n\n# check that CRS of the two datasets match\nprint(f'CRS of the lsat and tf datasets match: {tf.crs == lsat.rio.crs}')\n\n\nAfter squeeze:\ndimensions Frozen({'y': 731, 'x': 870})\ncoords: Coordinates:\n  * y            (y) float64 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n  * x            (x) float64 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n    spatial_ref  int64 0\nCRS of the lsat and tf datasets match: True\n\n\n\n\n\nIn the final step we will create a map showing the shortwave infrared/nir/ ed false color image together with the Thomas fire perimeter.\n\n\nCode\nfig, ax = plt.subplots()\n\n# remove axis\nax.axis('off')\n\n# plot Thomas fire perimeter\ntf.plot(ax=ax, color='none', edgecolor = '#483C32')\ntf_patch = mpatches.Patch(facecolor = 'none', \n                          edgecolor='#483C32', \n                          label='Thomas Fire Perimeter (2017)')\n\n# plot raster image of Santa Barbara area\nlsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(ax=ax, robust = True)\n\n# add legend\nax.legend(handles=[tf_patch], frameon=True, loc='upper right')\nax.set_title('Thomas Fire (Santa Barbara, 2017)')\n\n# annotate the data source\nax.annotate(\"Data: Microsoft Planetary Computer.https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed 28 Nov. 2023.\\nCalifornia Fire Perimeters (All).https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about. Accessed 28 Nov. 2023.\",\n            xy=(0.5, -0.15),  # Move the annotation lower to leave space for the x-axis title\n            fontsize=7, \n            xycoords='axes fraction',  \n            color='#555555',\n            ha='center')  \n\n# adjust the botton space of the figure\nplt.subplots_adjust(bottom=0.01)\n\n# display map\nplt.show()"
  },
  {
    "objectID": "posts/thomas-fire/thomasfire_aqi_analysis2.html#overview",
    "href": "posts/thomas-fire/thomasfire_aqi_analysis2.html#overview",
    "title": "thomas fire analysis",
    "section": "",
    "text": "In this notebook, we are going to analyze the impact of Thomas Fire on the air quality in Santa Barbara county in 2017. To do so, we will complete the following two tasks: 1. Visualize the Air Quality Index (AQI) in Santa Barbara County for 2017 and 2018. 2. Create a map to visualize the Thomas Fire scar.\n\n\nThe primary purpose of the notebook is to demonstrate environmental data analysis methods using both vector and raster data.\n\n\n\n\nPython libraries\n\nnumpy\npandas\npyplot and patches from matplotlib\nrioxarray\ngeopandas\nxarray\n\nJupyter Notebook\nGitHub\n\n\n\n\n\nData wrangling and exploration with Pandas\nGeospatial data wrangling with GeoPandas and Rioxarray\nTime series analysis\nMerging tabular and vector data\nVisualizing analysis results with a line plot\nCreating and customizing a map with raster and vector data\n\n\n\n\n\n\nAir Quality Index (AQI) data from the US Environmental Protection Agency[1] to visualize the impact on the AQI of the 2017 Thomas Fire in Santa Barbara County [2].\n\n\n\nA simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite [3]. Note: data should be used for visualization purposes only.\nInformation about Landsat bands from USGS:\n\nWhat are the band designations for the Landsat satellites?\nCommon Landsat Band Combinations\nHow do I use a scale factor with Landsat Level-2 science products?\n\n\n\n\nA prepared shapefile of fire perimeters in California during 2017. The complete file can be accessed in the CA state geoportal[4].\nData for datasets 2 and 3 is available on Google Drive in the file thomasfire_aqi_analysis.zip."
  },
  {
    "objectID": "posts/thomas-fire/thomasfire_aqi_analysis2.html#final-output",
    "href": "posts/thomas-fire/thomasfire_aqi_analysis2.html#final-output",
    "title": "thomas fire analysis",
    "section": "",
    "text": "The final outputs of the analysis include:\n\nA Line Plot depicting the time series analysis of the Air Quality Index (AQI) in Santa Barbara for 2017 and 2018. \nA Map with an overlay of the Thomas Fire scar on the Santa Barbara land cover. \n\n\n\n[1] AirData Website File Download Page. https://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI. Accessed 28 Nov. 2023. [2] “Thomas Fire.” Wikipedia, 9 Nov. 2023. Wikipedia, https://en.wikipedia.org/w/index.php?title=Thomas_Fire&oldid=1184323284. [3] Microsoft Planetary Computer. https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed 28 Nov. 2023. [4] California Fire Perimeters (All). https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about. Accessed 28 Nov. 2023."
  },
  {
    "objectID": "posts/thomas-fire/thomasfire_aqi_analysis2.html#import-libraries",
    "href": "posts/thomas-fire/thomasfire_aqi_analysis2.html#import-libraries",
    "title": "thomas fire analysis",
    "section": "",
    "text": "Code\n# import libraries with standard abbreviations\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches # for creating legends\n\nimport rioxarray as rioxr\nimport geopandas as gpd\nimport xarray as xr"
  },
  {
    "objectID": "posts/thomas-fire/thomasfire_aqi_analysis2.html#import-data",
    "href": "posts/thomas-fire/thomasfire_aqi_analysis2.html#import-data",
    "title": "thomas fire analysis",
    "section": "",
    "text": "Code\n# import Daily AQI by County data from url: Dataset 1\n# read in 2017 Daily AQI by County\nurl_aqi_17 = 'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip'\naqi_17 = pd.read_csv(url_aqi_17)\n\n# read in 2018 Daily AQI by County\nurl_aqi_18 = 'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip'\naqi_18 = pd.read_csv(url_aqi_18)\n\n\n\n\n\n\n\nCode\n# use rioxarray library to import netCDF file with geospatial features\nfp_lsat = 'data/landsat8-2018-01-26-sb-simplified.nc'\nlsat = rioxr.open_rasterio(fp_lsat)\n\n\n\n\n\n\n\nCode\n# use geopandas to import shape file with California fire perimeters \ncalfire = gpd.read_file(os.path.join(os.getcwd(), 'data', \n                                     'California_Fire_Perimeters_2017',\n                                     'California_Fire_Perimeters_2017.shp'))"
  },
  {
    "objectID": "posts/thomas-fire/thomasfire_aqi_analysis2.html#prepare-air-quality-data",
    "href": "posts/thomas-fire/thomasfire_aqi_analysis2.html#prepare-air-quality-data",
    "title": "thomas fire analysis",
    "section": "",
    "text": "Let’s take a quick look at the data before we proceed with data wrangling steps.\n\n\nCode\n# view the list of columns \nprint(aqi_17.columns)\n\n# view the first 2 rows of the dataframe aqi_17\naqi_17.head(2)\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object')\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n21\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n\nCode\n# view the list of columns \nprint(aqi_18.columns)\n\n# view the first 2 rows of the dataframe aqi_18\naqi_18.head(2)\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object')\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2018-01-02\n32\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2018-01-05\n34\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\nNotice that we currently have two separate dataframes. However, in order to analyze AQI for the two years, we need to combine them by appending the rows from one dataframe on top of the other. We will use the pandas function pd.concat() to do so.\nImportant: the columns of the two datasets have to match.\n\n\nCode\n# check whether the columns between the two datasets match\nprint(f'Do columns match?\\n {aqi_18.columns == aqi_17.columns} \\n')\n\n# check whether the column datatypes between the two datasets match\nprint(f'Do datatypes of the columns match?\\n{aqi_18.dtypes == aqi_17.dtypes}')\n\n\nDo columns match?\n [ True  True  True  True  True  True  True  True  True  True] \n\nDo datatypes of the columns match?\nState Name                   True\ncounty Name                  True\nState Code                   True\nCounty Code                  True\nDate                         True\nAQI                          True\nCategory                     True\nDefining Parameter           True\nDefining Site                True\nNumber of Sites Reporting    True\ndtype: bool\n\n\nNote: since the column names and datatypes of the two datasets match exaclty we can combine the them into a single dataframe. Let’s check how many records we should expect in the combined dataframe.\n\n\nCode\n# get the count of rows that have state = CA and county = Santa Barbara in the dataframe aqi_17\naqi_17_count = len(aqi_17)\n\n# get the count of rows that have state = CA and county = Santa Barbara in the dataframe aqi_18\naqi_18_count = len(aqi_18)\n\n# get the total count of rows we expect in the combined dataframe\ntot_count = aqi_17_count + aqi_18_count\nprint(f'Combined dataframe should have total number of rows: {tot_count}')  \n\n\nCombined dataframe should have total number of rows: 654338\n\n\n\n\nCode\n# combine two datasets aqi_17 and aqi_18 in a single one\naqi = pd.concat([aqi_17, aqi_18])\n\n# check the total count of rows matches the expected number\naqi_count = len(aqi)\nprint(f'Count of rows in the combined aqi dataframe: {aqi_count}')\nprint(f'Is the total number of rows in the combined dataframe as expected? {aqi_count == tot_count} \\n')\n\n# check the first 2 rows of the combined dataframe\naqi.head(2)\n\n\nCount of rows in the combined aqi dataframe: 654338\nIs the total number of rows in the combined dataframe as expected? True \n\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n21\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\nNotice that column names have inconsistent case and spaces in between the words. Let’s update the column names to snake_case 🐍 to simplify data manipulation.\n\n\nCode\n# update the column names case to snake_case\naqi.columns = aqi.columns.str.lower().str.replace(' ','_')\n# check that the column names are updated\nprint(aqi.columns)\n\n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object')\n\n\nFor our analysis we need only AQI data from the Santa Barbara county. Let’s create a new dataframeaqi_sb filtered to Santa Barbara county. Additionally, we can remove unecessary columns state_name, county_name, state_code and county_code from the new dataframe.\n\n\nCode\n# select the records where county_name = 'Santa Barbara' from the combined dataset aqi\naqi_sb = aqi.loc[aqi.county_name == 'Santa Barbara'].copy()\n\n# remove the state_name, county_name, state_code and county_code columns from aqi_sb\naqi_sb = aqi_sb.drop(columns = ['state_name', 'county_name', 'state_code', 'county_code'])\n\n\n\n\nCode\n# check the data types of the columns\nprint(aqi_sb.dtypes)\n\n\ndate                         object\naqi                           int64\ncategory                     object\ndefining_parameter           object\ndefining_site                object\nnumber_of_sites_reporting     int64\ndtype: object\n\n\n⚠️ Date column has type object rather than datetime as expected.\nWe will make the following changes to facilitate working with dates:\n\nConvert the date column of aqi_sb to a datetime object.\nSet the date column as the index for aqi_sb dataframe.\n\n\n\nCode\n# update date column values of aqi_sb to datetype object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n      \n# update the index of aqi_sb to be the date column\naqi_sb = aqi_sb.set_index('date')\n\n# check column date is updated\nprint(aqi_sb.index)\n\n\nDatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03', '2017-01-04',\n               '2017-01-05', '2017-01-06', '2017-01-07', '2017-01-08',\n               '2017-01-09', '2017-01-10',\n               ...\n               '2018-12-22', '2018-12-23', '2018-12-24', '2018-12-25',\n               '2018-12-26', '2018-12-27', '2018-12-28', '2018-12-29',\n               '2018-12-30', '2018-12-31'],\n              dtype='datetime64[ns]', name='date', length=730, freq=None)\n\n\nOur current dataframe contains daily values of AQI, which can create short-term fluctuations and noise in data. We’ll apply a 5-day rolling average to smooth out the data and improve the quality of the analysis. To achieve this we will create a new variable, five_day_average, using the pandas method rolling.\nNote: rolling() is a method for pandas.series that provides rolling window calculations. This is a lazy method (think groupby), we need to specify what we want to calculate over each window. It returns pd.Series as ouput.\n\n\nCode\n# calculate 5-day rolling average AQI\n# the parameter '5D' indicates we want the window to be 5 days\naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean() \n\n# view the first two rows of the updated dataframe\naqi_sb.head(2)\n\n\n\n\n\n\n\n\n\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\nfive_day_average\n\n\ndate\n\n\n\n\n\n\n\n\n\n\n2017-01-01\n39\nGood\nOzone\n06-083-4003\n12\n39.0\n\n\n2017-01-02\n36\nGood\nOzone\n06-083-4003\n11\n37.5"
  },
  {
    "objectID": "posts/thomas-fire/thomasfire_aqi_analysis2.html#visualize-aqi-output",
    "href": "posts/thomas-fire/thomasfire_aqi_analysis2.html#visualize-aqi-output",
    "title": "thomas fire analysis",
    "section": "",
    "text": "In the next step, we will create a line plot with daily AQI and 5-day average AQI to visualize the impact of the Thomas Fire (December 2017) on air quality in Santa Barbara County.\n\n\nCode\n# plot both the daily AQI and the 5-day average\nfig, ax = plt.subplots()\n\naqi_sb.aqi.plot(ax=ax,\n                color = '#fecc5c')\naqi_sb.five_day_average.plot(ax=ax,\n                color = '#a50f15')\n\n# update axis\nax.set_title('Daily Average vs 5 day Average AQI in Santa Barbara (2017-2018)')\nax.set_xlabel('Period')\nax.set_ylabel('AQI')\nax.legend(['AQI Daily Average', 'AQI 5-day Average'])\n\n# annotate the data source\nax.annotate(\"Data: AirData Website File Download Page.\\nhttps://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI. Accessed 28 Nov. 2023\",\n            xy=(0.5, -0.15), \n            fontsize=7, \n            xycoords='axes fraction',  \n            color='#555555',\n            ha='center',\n            va='top')  \n\n# adjust the botton space of the figure\nplt.subplots_adjust(bottom=0.01)\n\nplt.show\n\n\n&lt;function matplotlib.pyplot.show(close=None, block=None)&gt;\n\n\n\n\n\nFrom the graph we can see a significant increase in both the daily average and 5-day rolling average in December 2017 compared to the rest of the year, which coincides with the Thomas Fire event. During this period, the AQI exceeded 200, falling into the very unhealthy category. According to AQI standards, at this level, the risk of health effects is increased for everyone."
  },
  {
    "objectID": "posts/thomas-fire/thomasfire_aqi_analysis2.html#prepare-geospatial-data",
    "href": "posts/thomas-fire/thomasfire_aqi_analysis2.html#prepare-geospatial-data",
    "title": "thomas fire analysis",
    "section": "",
    "text": "First, let’s inspect geospatial datasets.\n\n\nCode\n# view the first two records of imported shape file data\ncalfire.head(2)\n\n\n\n\n\n\n\n\n\nindex\nOBJECTID\nYEAR_\nSTATE\nAGENCY\nUNIT_ID\nFIRE_NAME\nINC_NUM\nALARM_DATE\nCONT_DATE\n...\nGIS_ACRES\nCOMMENTS\nCOMPLEX_NA\nCOMPLEX_IN\nIRWINID\nFIRE_NUM\nDECADES\nSHAPE_Leng\nSHAPE_Area\ngeometry\n\n\n\n\n0\n19836\n41429\n2017\nCA\nCCO\nVNC\nBROOK\n00042450\n2017-05-23\n2017-05-24\n...\n10.043819\nper walked track\nNone\nNone\nNone\nNone\n2010\n1246.055781\n59473.666651\nPOLYGON ((-13229812.974 4046876.486, -13229786...\n\n\n1\n19837\n41430\n2017\nCA\nCCO\nVNC\nPACIFIC\n00075307\n2017-09-09\n2017-09-09\n...\n1.190109\nFinal Walked track. Small spot to the north east\nNone\nNone\nNone\nNone\n2010\n561.418202\n7081.369481\nPOLYGON ((-13286872.985 4074523.355, -13286895...\n\n\n\n\n2 rows × 23 columns\n\n\n\n\n\nCode\nprint(f'calfire dataset shape: {calfire.shape}')\nprint(f'calfire dataset crs: {calfire.crs}')\nprint(f'calfire dataset geometry:\\n {calfire.geometry.head()}')\n\n# visualize calfire data\ncalfire.plot(color = 'none')\n\n\ncalfire dataset shape: (608, 23)\ncalfire dataset crs: epsg:3857\ncalfire dataset geometry:\n 0    POLYGON ((-13229812.974 4046876.486, -13229786...\n1    POLYGON ((-13286872.985 4074523.355, -13286895...\n2    POLYGON ((-13244637.580 4056332.530, -13244620...\n3    POLYGON ((-13229521.754 4046254.111, -13229510...\n4    POLYGON ((-13229663.036 4046858.853, -13229667...\nName: geometry, dtype: geometry\n\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\nCalifornia fire perimeter dataset includes the list of all fires in California during 2017. For our analysis, we are interested only in Thomas fire that occured that year.\nTherefore, we need to filter the dataset to the rows with Thomas fire.\n\n\nCode\n# update the column names case to snake_case\ncalfire.columns = calfire.columns.str.lower().str.replace(' ','_')\nprint(calfire.columns)\n\n# find the value that corresponds to Thomas fire\ncalfire[calfire.fire_name.str.contains('Thomas', case=False, na=False)]['fire_name'].unique()\n\n\nIndex(['index', 'objectid', 'year_', 'state', 'agency', 'unit_id', 'fire_name',\n       'inc_num', 'alarm_date', 'cont_date', 'cause', 'c_method', 'objective',\n       'gis_acres', 'comments', 'complex_na', 'complex_in', 'irwinid',\n       'fire_num', 'decades', 'shape_leng', 'shape_area', 'geometry'],\n      dtype='object')\n\n\narray(['THOMAS'], dtype=object)\n\n\nWe only have one record with fire_name = THOMAS. This is the record that we want to use for our analysis.\n\n\nCode\n# create a new dataframe with Thomas fire details\ntf = calfire[calfire.fire_name == 'THOMAS']\n\n\n\n\nCode\n# explore data of the netCDF file\n\nprint(f'lsat CRS: {lsat.rio.crs}')\n\n# print shape and data type\nprint('shape: ', lsat.rio.shape)\nprint('data type: ', type(lsat), '\\n')\n# print(lsat)\n\n# make a simple map to visualize lsat dataset\nlsat['red'].plot()\n\n\nlsat CRS: EPSG:32611\nshape:  (731, 870)\ndata type:  &lt;class 'xarray.core.dataset.Dataset'&gt; \n\n\n\n&lt;matplotlib.collections.QuadMesh at 0x7f786aef5ee0&gt;\n\n\n\n\n\n⚠️ Notice the following two details:\n\nThe Coordinate Reference Systems (CRS) of the two datasets are different. Since we want to overlay the Thomas Fire perimeter on the Santa Barbara County land cover, we need to ensure that the CRSs of the two datasets are the same. To achieve this, we will reproject the CRS of the tf dataset into the CRS of the lsat dataset.\nThe lsat dataset includes an additional dimension, the band, which makes it a 3-dimensional object. We are going to convert it into a 2-dimensional dataset by dropping the band dimension.\n\n\n\nCode\n# drop an extra dimension \"band\" from lsat dataset\nlsat = lsat.squeeze().drop('band')\n\n# check that band dimension has been dropped\nprint(f'After squeeze:\\ndimensions {lsat.dims}\\ncoords: {lsat.coords}')\n\n# update CRS of the shape file to lsat CRS\ntf = tf.to_crs(crs = lsat.rio.crs)\n\n# check that CRS of the two datasets match\nprint(f'CRS of the lsat and tf datasets match: {tf.crs == lsat.rio.crs}')\n\n\nAfter squeeze:\ndimensions Frozen({'y': 731, 'x': 870})\ncoords: Coordinates:\n  * y            (y) float64 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n  * x            (x) float64 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n    spatial_ref  int64 0\nCRS of the lsat and tf datasets match: True"
  },
  {
    "objectID": "posts/thomas-fire/thomasfire_aqi_analysis2.html#create-a-map",
    "href": "posts/thomas-fire/thomasfire_aqi_analysis2.html#create-a-map",
    "title": "thomas fire analysis",
    "section": "",
    "text": "In the final step we will create a map showing the shortwave infrared/nir/ ed false color image together with the Thomas fire perimeter.\n\n\nCode\nfig, ax = plt.subplots()\n\n# remove axis\nax.axis('off')\n\n# plot Thomas fire perimeter\ntf.plot(ax=ax, color='none', edgecolor = '#483C32')\ntf_patch = mpatches.Patch(facecolor = 'none', \n                          edgecolor='#483C32', \n                          label='Thomas Fire Perimeter (2017)')\n\n# plot raster image of Santa Barbara area\nlsat[['swir22', 'nir08', 'red']].to_array().plot.imshow(ax=ax, robust = True)\n\n# add legend\nax.legend(handles=[tf_patch], frameon=True, loc='upper right')\nax.set_title('Thomas Fire (Santa Barbara, 2017)')\n\n# annotate the data source\nax.annotate(\"Data: Microsoft Planetary Computer.https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed 28 Nov. 2023.\\nCalifornia Fire Perimeters (All).https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about. Accessed 28 Nov. 2023.\",\n            xy=(0.5, -0.15),  # Move the annotation lower to leave space for the x-axis title\n            fontsize=7, \n            xycoords='axes fraction',  \n            color='#555555',\n            ha='center')  \n\n# adjust the botton space of the figure\nplt.subplots_adjust(bottom=0.01)\n\n# display map\nplt.show()"
  }
]